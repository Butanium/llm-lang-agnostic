{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIVE_MODE = False  # Set to True to run the notebook interactively\n",
    "\n",
    "import sys\n",
    "\n",
    "if INTERACTIVE_MODE:\n",
    "    sys.path.append(\"../src\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 3\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    sys.path.append(\"./src\")\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "from random import shuffle\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"obj_patch_translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "batch_size = 8\n",
    "model = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "device = \"auto\"\n",
    "remote = False\n",
    "num_few_shot = 5\n",
    "exp_id = None\n",
    "extra_args = []\n",
    "use_tl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--num-patches\", type=int, default=-1)\n",
    "pargs = parser.parse_args(extra_args)\n",
    "num_patches = pargs.num_patches\n",
    "\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    use_tl=use_tl,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import (\n",
    "    run_prompts,\n",
    ")\n",
    "from interventions import (\n",
    "    object_lens,\n",
    "    collect_activations,\n",
    "    collect_activations_batched,\n",
    "    get_num_layers,\n",
    ")\n",
    "from prompt_tools import translation_prompts, get_obj_id\n",
    "from load_dataset import get_word_translation_dataset as get_translations\n",
    "\n",
    "from utils import ulist\n",
    "from display_utils import plot_topk_tokens, plot_results, plot_k_results, k_subplots\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def object_patching_plot(\n",
    "    source_lang_pairs,\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    extra_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    num_pairs=200,\n",
    "    exp_id=exp_id,\n",
    "    k=4,\n",
    "    remote=remote,\n",
    "):\n",
    "    \"\"\"\n",
    "    Experiment 2 of the paper:\n",
    "    - For each source_lang_pairs, construct a prompt translating the same concept (e.g. DOG):\n",
    "    L1: \"CAT^L1\" - L2: \"CAT^L2\"\n",
    "    ...\n",
    "    L1: \"DOG^L1\n",
    "\n",
    "    - Collect activation at the last token of the prompt and generate a mean latent representation for each layer\n",
    "\n",
    "    - For each layer `j`: Run the target prompts which are translations from the input_lang to the target_lang. During the forward pass, patch at the last token of the concept to be translated with the mean latent representation of the source prompts from `j` to the last layer.\n",
    "\n",
    "    We plot both the probabilities you get from the mean latent and the probabilities you get from the first source_lang_pairs latent.\n",
    "    \"\"\"\n",
    "    source_lang_pairs = np.array(source_lang_pairs)\n",
    "    if extra_langs is None:\n",
    "        extra_langs = []\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global source_df, target_df, target_prompts, target_probs, latent_probs, source_prompts, _source_prompts, _target_prompts\n",
    "    if exp_id is None:\n",
    "        exp_id = str(int(time()))\n",
    "    else:\n",
    "        exp_id = str(exp_id)\n",
    "    source_df = get_translations(\n",
    "        \"en\",\n",
    "        ulist([*source_lang_pairs.flatten(), input_lang, target_lang, *extra_langs]),\n",
    "        num_words,\n",
    "    )\n",
    "    target_df = get_translations(\n",
    "        input_lang,\n",
    "        ulist([*source_lang_pairs.flatten(), target_lang, *extra_langs]),\n",
    "        num_words,\n",
    "    )\n",
    "\n",
    "    _source_prompts = list(\n",
    "        zip(\n",
    "            *[\n",
    "                translation_prompts(\n",
    "                    source_df,\n",
    "                    nn_model.tokenizer,\n",
    "                    inp_lang,\n",
    "                    targ_lang,\n",
    "                    [target_lang, *extra_langs],\n",
    "                    augment_tokens=False,\n",
    "                    n=num_few_shot,\n",
    "                )\n",
    "                for inp_lang, targ_lang in source_lang_pairs\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    _target_prompts = translation_prompts(\n",
    "        target_df,\n",
    "        nn_model.tokenizer,\n",
    "        input_lang,\n",
    "        target_lang,\n",
    "        [*extra_langs],  # [*list(zip(*source_lang_pairs))[1], *extra_langs],\n",
    "        augment_tokens=False,\n",
    "        n=num_few_shot,\n",
    "    )\n",
    "\n",
    "    collected_pairs = 0\n",
    "    source_prompts = []\n",
    "    target_prompts = []\n",
    "    source_target = list(itertools.product(source_df.iterrows(), target_df.iterrows()))\n",
    "    shuffle(source_target)\n",
    "\n",
    "    for (i, source_row), (j, target_row) in source_target:\n",
    "        if source_row[\"word_original\"] == target_row[\"word_original\"]:\n",
    "            continue\n",
    "        src_p = _source_prompts[i]\n",
    "        targ_p = deepcopy(_target_prompts[j])\n",
    "        latent_tokens = {f\"source_{target_lang}\": src_p[0].latent_tokens[target_lang]}\n",
    "        latent_tokens.update(**targ_p.latent_tokens)\n",
    "        targ_p.latent_tokens = latent_tokens\n",
    "        targ_p.latent_strings[f\"sources\"] = ulist(\n",
    "            sum([p.target_strings for p in src_p], [])\n",
    "        )\n",
    "        targ_p.latent_strings[f\"source_{target_lang}\"] = src_p[0].latent_strings[\n",
    "            target_lang\n",
    "        ]\n",
    "        for lang in extra_langs:\n",
    "            targ_p.latent_tokens[f\"src + tgt {lang}\"] = ulist(\n",
    "                targ_p.latent_tokens[lang] + src_p[0].latent_tokens[lang]\n",
    "            )\n",
    "            targ_p.latent_strings[f\"src + tgt {lang}\"] = ulist(\n",
    "                targ_p.latent_strings[lang] + src_p[0].latent_strings[lang]\n",
    "            )\n",
    "            del targ_p.latent_tokens[lang]\n",
    "        if targ_p.has_no_collisions():\n",
    "            source_prompts.append(src_p)\n",
    "            target_prompts.append(targ_p)\n",
    "            collected_pairs += 1\n",
    "        if collected_pairs >= num_pairs:\n",
    "            break\n",
    "    if collected_pairs < num_pairs:\n",
    "        print(\n",
    "            f\"Could only collect {collected_pairs} pairs for {source_lang_pairs.tolist()} - {input_lang} -> {target_lang}, skipping...\"\n",
    "        )\n",
    "        return\n",
    "    source_prompts = np.array(source_prompts)\n",
    "    source_prompts_str = np.array(\n",
    "        [['\"'.join(p.prompt.split('\"')[:-2]) for p in ps] for ps in source_prompts]\n",
    "    )\n",
    "    idx = get_obj_id(target_prompts[0].prompt, nn_model.tokenizer)\n",
    "\n",
    "    def object_patching(\n",
    "        nn_model, prompt_batch, scan, source_prompt_batch=None, only_first=False\n",
    "    ):\n",
    "        offset = object_patching.offset\n",
    "        batch_size = len(prompt_batch)\n",
    "        if source_prompt_batch is None:\n",
    "            source_prompt_batch = source_prompts_str[offset : offset + batch_size]\n",
    "        if only_first:\n",
    "            source_prompt_batch = source_prompt_batch[:, :1]\n",
    "        hiddens = collect_activations_batched(\n",
    "            nn_model,\n",
    "            source_prompt_batch.flatten(),\n",
    "            batch_size=batch_size,\n",
    "            remote=remote,\n",
    "        )\n",
    "        hiddens = hiddens.transpose(0, 1)  # (all_prompts, layer, hidden_size)\n",
    "        hiddens = hiddens.reshape(\n",
    "            batch_size, source_prompt_batch.shape[1], get_num_layers(nn_model), -1\n",
    "        ).mean(\n",
    "            dim=1\n",
    "        )  # (batch_size, num_layers, hidden_size)\n",
    "        hiddens = hiddens.transpose(0, 1)  # (num_layers, batch_size, hidden_size)\n",
    "        object_patching.offset += batch_size\n",
    "        return object_lens(\n",
    "            nn_model,\n",
    "            prompt_batch,\n",
    "            idx,\n",
    "            hiddens=hiddens,\n",
    "            scan=scan,\n",
    "            num_patches=num_patches,\n",
    "            remote=remote,\n",
    "        )\n",
    "\n",
    "    object_patching.offset = 0\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model,\n",
    "        target_prompts,\n",
    "        batch_size=batch_size,\n",
    "        get_probs=object_patching,\n",
    "        tqdm=tqdm,\n",
    "    )\n",
    "\n",
    "    object_patching.offset = 0\n",
    "    of_target_probs, of_latent_probs = run_prompts(\n",
    "        nn_model,\n",
    "        target_prompts,\n",
    "        batch_size=batch_size,\n",
    "        get_probs=object_patching,\n",
    "        get_probs_kwargs=dict(only_first=True),\n",
    "        tqdm=tqdm,\n",
    "    )\n",
    "\n",
    "    # Get the baseline to normalize the plots\n",
    "    all_source_prompts = source_prompts.flatten()\n",
    "    source_prompts_probs = (\n",
    "        run_prompts(\n",
    "            nn_model,\n",
    "            all_source_prompts,\n",
    "            batch_size=batch_size,\n",
    "            get_probs_kwargs=dict(remote=remote),\n",
    "            tqdm=tqdm,\n",
    "        )[0]\n",
    "        .squeeze()\n",
    "        .reshape(len(source_prompts), -1)\n",
    "    )\n",
    "\n",
    "    target_prompts_probs, _ = run_prompts(\n",
    "        nn_model,\n",
    "        target_prompts,\n",
    "        batch_size=batch_size,\n",
    "        get_probs_kwargs=dict(remote=remote),\n",
    "        tqdm=tqdm,\n",
    "    )\n",
    "\n",
    "    json_dic = {\n",
    "        target_lang: target_probs.tolist(),\n",
    "        \"source prompt probs\": source_prompts_probs.squeeze().tolist(),\n",
    "        \"target prompt probs\": target_prompts_probs.squeeze().tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    json_dic[\"only first\"] = {target_lang: of_target_probs.tolist()}\n",
    "    for label, probs in of_latent_probs.items():\n",
    "        json_dic[\"only first\"][label] = probs.tolist()\n",
    "    pref = \"_\".join(\"-\".join(ls) for ls in source_lang_pairs)\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / exp_name\n",
    "        / (f\"{pref}-{input_lang}_{target_lang}-\")\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    pref = pref.replace(\"_\", \" \")\n",
    "    title = f\"{model_name}: ObjPatch from ({pref}) into ({input_lang} -> {target_lang})\"\n",
    "    plot_results(\n",
    "        ax,\n",
    "        target_probs,\n",
    "        latent_probs,\n",
    "        target_lang,\n",
    "        source_baseline=source_prompts_probs.mean(),\n",
    "        target_baseline=target_prompts_probs.mean(),\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    plot_results(ax, of_target_probs, of_latent_probs, target_lang)\n",
    "    ax.legend()\n",
    "    pref2 = pref.split(\" \")[0]\n",
    "    ax.set_title(\n",
    "        f\"{model_name}: ObjPatch from ({pref2}) into ({input_lang} -> {target_lang}\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \"_only_first.png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = k_subplots(k)\n",
    "    plot_k_results(axes, target_probs, latent_probs, target_lang, k)\n",
    "    axes[k - 1].legend()\n",
    "    fig.suptitle(title)\n",
    "    plt_file = path / (exp_id + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    # Compute a single example\n",
    "    json_meta = {}\n",
    "    for i in range(k):\n",
    "        json_meta[i] = {\n",
    "            \"source pairs\": source_lang_pairs.tolist(),\n",
    "            \"input lang\": input_lang,\n",
    "            \"target lang\": target_lang,\n",
    "            \"source prompt\": {\n",
    "                \"-\".join(l) + \" \" + str(j): source_prompts_str[i][j]\n",
    "                for j, l in enumerate(source_lang_pairs)\n",
    "            },\n",
    "            \"source prompt target\": {\n",
    "                \"-\".join(l) + \" \" + str(j): source_prompts[i][j].target_strings\n",
    "                for j, l in enumerate(source_lang_pairs)\n",
    "            },\n",
    "            \"source prompt latent\": {\n",
    "                \"-\".join(l) + \" \" + str(j): source_prompts[i][j].latent_strings\n",
    "                for j, l in enumerate(source_lang_pairs)\n",
    "            },\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = [p.prompt for p in target_prompts[:k]]\n",
    "    probs = object_patching(\n",
    "        nn_model,\n",
    "        target_prompt_batch,\n",
    "        scan=True,\n",
    "        source_prompt_batch=source_prompts_str[:k],\n",
    "    )\n",
    "    file = path / (exp_id + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (exp_id + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_pairs = [(\"de\", \"it\"), (\"nl\", \"fi\"), (\"zh\", \"es\"), (\"es\", \"ru\"), (\"ru\", \"ko\")]\n",
    "paper_ins = [\"de\", \"nl\", \"zh\", \"es\", \"ru\"]\n",
    "paper_args = [\n",
    "    [[(l, \"hi\") for l in paper_ins], \"fr\", \"et\"],\n",
    "    (paper_pairs, \"fr\", \"zh\"),\n",
    "]\n",
    "for pargs in paper_args:\n",
    "    object_patching_plot(*pargs, extra_langs=[\"en\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
