{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIVE_MODE = False  # Set to True to run the notebook interactively\n",
    "\n",
    "import sys\n",
    "\n",
    "if INTERACTIVE_MODE:\n",
    "    sys.path.append(\"../src\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 3\n",
    "else:\n",
    "    sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "batch_size = 64\n",
    "model = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "device = \"auto\"\n",
    "remote = False\n",
    "num_few_shot = 5\n",
    "exp_id = None\n",
    "extra_args = []\n",
    "use_tl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "pargs = parser.parse_args(extra_args)\n",
    "\n",
    "\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    use_tl=use_tl,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_tools import run_prompts\n",
    "from interventions import TargetPromptBatch, patchscope_lens\n",
    "from prompt_tools import (\n",
    "    translation_prompts,\n",
    "    get_shifted_prompt_pairs,\n",
    "    NotEnoughPromptsError,\n",
    ")\n",
    "\n",
    "from load_dataset import get_word_translation_dataset as get_translations\n",
    "\n",
    "from utils import ulist\n",
    "from display_utils import plot_k_results, plot_topk_tokens, plot_results, k_subplots\n",
    "\n",
    "\n",
    "def shifted_translation_plot(\n",
    "    source_input_lang,\n",
    "    source_output_lang,\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    extra_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    num_pairs=200,\n",
    "    exp_id=exp_id,\n",
    "    k=4,\n",
    "    remote=remote,\n",
    "):\n",
    "    \"\"\"\n",
    "    Patchscope with source hidden from:\n",
    "    index -1 and Prompt = source_input_lang: A -> source_target_lang:\n",
    "    Into target prompt:\n",
    "    into index = -1, prompt = input_lang: A -> target_lang:\n",
    "    Then plot with latent_langs, target_lang, source_target_lang\n",
    "    \"\"\"\n",
    "    if extra_langs is None:\n",
    "        extra_langs = []\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global source_df, target_df, target_prompts, target_probs, latent_probs, source_prompts\n",
    "    if exp_id is None:\n",
    "        exp_id = str(int(time()))\n",
    "    else:\n",
    "        exp_id = str(exp_id)\n",
    "    source_df = get_translations(\n",
    "        source_input_lang,\n",
    "        ulist([source_output_lang, input_lang, target_lang, *extra_langs]),\n",
    "        num_words,\n",
    "    )\n",
    "    target_df = get_translations(\n",
    "        input_lang,\n",
    "        ulist([source_output_lang, source_input_lang, target_lang, *extra_langs]),\n",
    "        num_words,\n",
    "    )\n",
    "\n",
    "    _source_prompts = translation_prompts(\n",
    "        source_df,\n",
    "        nn_model.tokenizer,\n",
    "        source_input_lang,\n",
    "        source_output_lang,\n",
    "        [target_lang, *extra_langs],\n",
    "        augment_tokens=False,\n",
    "        n=num_few_shot,\n",
    "    )\n",
    "    _target_prompts = translation_prompts(\n",
    "        target_df,\n",
    "        nn_model.tokenizer,\n",
    "        input_lang,\n",
    "        target_lang,\n",
    "        [source_output_lang, *extra_langs],\n",
    "        augment_tokens=False,\n",
    "        n=num_few_shot,\n",
    "    )\n",
    "    try:\n",
    "        source_prompts, target_prompts = get_shifted_prompt_pairs(\n",
    "            source_df,\n",
    "            target_df,\n",
    "            _source_prompts,\n",
    "            _target_prompts,\n",
    "            source_input_lang,\n",
    "            source_output_lang,\n",
    "            input_lang,\n",
    "            target_lang,\n",
    "            extra_langs,\n",
    "            num_pairs,\n",
    "            merge_extra_langs=True,\n",
    "        )\n",
    "    except NotEnoughPromptsError:\n",
    "        return\n",
    "\n",
    "    source_prompts_str = [p.prompt for p in source_prompts]\n",
    "\n",
    "    def transverse_patchscope(nn_model, prompt_batch, scan):\n",
    "        offset = transverse_patchscope.offset\n",
    "        target_pathscope_prompts = TargetPromptBatch.from_prompts(prompt_batch, -1)\n",
    "        source_prompt_batch = source_prompts_str[offset : offset + len(prompt_batch)]\n",
    "        transverse_patchscope.offset += len(prompt_batch)\n",
    "        return patchscope_lens(\n",
    "            nn_model,\n",
    "            source_prompt_batch,\n",
    "            target_pathscope_prompts,\n",
    "            scan=scan,\n",
    "            remote=remote,\n",
    "        )\n",
    "\n",
    "    transverse_patchscope.offset = 0\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=transverse_patchscope\n",
    "    )\n",
    "\n",
    "    # Get the baseline to normalize the plots\n",
    "    source_prompts_probs, _ = run_prompts(\n",
    "        nn_model,\n",
    "        source_prompts,\n",
    "        batch_size=batch_size,\n",
    "        get_prob_kwargs=dict(remote=remote),\n",
    "    )\n",
    "    target_prompts_probs, _ = run_prompts(\n",
    "        nn_model,\n",
    "        target_prompts,\n",
    "        batch_size=batch_size,\n",
    "        get_prob_kwargs=dict(remote=remote),\n",
    "    )\n",
    "\n",
    "    json_dic = {\n",
    "        target_lang: target_probs.tolist(),\n",
    "        \"source prompt probs\": source_prompts_probs.squeeze().tolist(),\n",
    "        \"target prompt probs\": target_prompts_probs.squeeze().tolist(),\n",
    "    }\n",
    "    for label, probs in latent_probs.items():\n",
    "        json_dic[label] = probs.tolist()\n",
    "    path = (\n",
    "        Path(\"results\")\n",
    "        / model_name\n",
    "        / \"shifted_translation\"\n",
    "        / (f\"{source_input_lang}_{source_output_lang}-{input_lang}_{target_lang}\")\n",
    "    )\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    json_file = path / (exp_id + \".json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Raw probabilities plot\n",
    "    plot_results(\n",
    "        ax,\n",
    "        target_probs,\n",
    "        latent_probs,\n",
    "        target_lang,\n",
    "        source_baseline=source_prompts_probs.mean(),\n",
    "        target_baseline=target_prompts_probs.mean(),\n",
    "    )\n",
    "    ax.legend()\n",
    "    title = f\"{model_name}: HeteroPatch from ({source_input_lang} -> {source_output_lang}) into ({input_lang} -> {target_lang})\"\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plot_file = path / (exp_id + \".png\")\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot k examples\n",
    "    fig, axes = k_subplots(k)\n",
    "    plot_k_results(axes, target_probs, latent_probs, target_lang, k=k)\n",
    "    axes[k - 1].legend()\n",
    "    fig.suptitle(title)\n",
    "    plt_file = path / (exp_id + \"_k.png\")\n",
    "    fig.savefig(plt_file, dpi=300, bbox_inches=\"tight\")\n",
    "    fig.show()\n",
    "    # Compute a single example\n",
    "    json_meta = {}\n",
    "    for i in range(k):\n",
    "        json_meta[i] = {\n",
    "            \"source input lang\": source_input_lang,\n",
    "            \"source target lang\": source_output_lang,\n",
    "            \"input lang\": input_lang,\n",
    "            \"target lang\": target_lang,\n",
    "            \"source prompt\": source_prompts_str[i],\n",
    "            \"source prompt target\": source_prompts[i].target_strings,\n",
    "            \"source prompt latent\": source_prompts[i].latent_strings,\n",
    "            \"target prompt\": target_prompts[i].prompt,\n",
    "            \"target prompt target\": target_prompts[i].target_strings,\n",
    "            \"target prompt latent\": target_prompts[i].latent_strings,\n",
    "        }\n",
    "    json_df = pd.DataFrame(json_meta)\n",
    "    with pd.option_context(\n",
    "        \"display.max_colwidth\",\n",
    "        None,\n",
    "        \"display.max_columns\",\n",
    "        None,\n",
    "        \"display.max_rows\",\n",
    "        None,\n",
    "    ):\n",
    "        display(json_df)\n",
    "    target_prompt_batch = TargetPromptBatch.from_prompts(\n",
    "        [p.prompt for p in target_prompts[:k]], -1\n",
    "    )\n",
    "    probs = patchscope_lens(\n",
    "        nn_model, source_prompts_str[:k], target_prompt_batch, remote=remote\n",
    "    )\n",
    "    file = path / (exp_id + \"_heatmap.png\")\n",
    "    plot_topk_tokens(probs, nn_model, title=title, file=file)\n",
    "\n",
    "    meta_file = path / (exp_id + \"_heatmap.meta.json\")\n",
    "    with open(meta_file, \"w\") as f:\n",
    "        json.dump(json_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_args = [\n",
    "    (\"de\", \"it\", \"fr\", \"zh\"),\n",
    "]\n",
    "for args in paper_args:\n",
    "    shifted_translation_plot(*args, extra_langs=[\"en\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
