{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "import gc\n",
    "from random import shuffle\n",
    "\n",
    "_ = th.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"mean_repr_def\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "batch_size = 8\n",
    "model = \"google/gemma-2-2b\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "device = \"auto\"\n",
    "remote = False\n",
    "num_few_shot = 5\n",
    "exp_id = \"test\"\n",
    "extra_args = []\n",
    "use_tl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging...\n",
      "Interactive mode!\n"
     ]
    }
   ],
   "source": [
    "INTERACTIVE_MODE = exp_id == \"test\"  # Set to True to run the notebook interactively\n",
    "DEBUG = exp_id == \"test\" and True\n",
    "import sys\n",
    "if DEBUG:\n",
    "    print(\"Debugging...\")\n",
    "if INTERACTIVE_MODE:\n",
    "    print(\"Interactive mode!\")\n",
    "    exp_id = \"test\" + str(int(time()))\n",
    "    sys.path.append(\"../src\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "else:\n",
    "    sys.path.append(\"./src\")\n",
    "    from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nnterp import load_model\n",
    "from dlabutils import model_path as dlab_model_path\n",
    "from argparse import ArgumentParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--gen-batch-size\", type=int, default=batch_size // 2)\n",
    "parser.add_argument(\n",
    "    \"--embeddings-model\",\n",
    "    type=str,\n",
    "    default=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    ")\n",
    "parser.add_argument(\"--emb-batch-size\", type=int, default=256)\n",
    "parser.add_argument(\"--debug\", action=\"store_true\")\n",
    "pargs = parser.parse_args(extra_args)\n",
    "DEBUG = pargs.debug\n",
    "if DEBUG:\n",
    "    print(\"/!\\\\ Debugging...\")\n",
    "    exp_name = \"debug-\" + exp_name\n",
    "gen_batch_size = pargs.gen_batch_size\n",
    "emb_batch_size = pargs.emb_batch_size\n",
    "embeddings_model = SentenceTransformer(\n",
    "    dlab_model_path(pargs.embeddings_model), device=device if device != \"auto\" else None\n",
    ")\n",
    "\n",
    "if model_path is None:\n",
    "    model_path = dlab_model_path(model)\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    use_tl=use_tl,\n",
    "    no_space_on_bos=True,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer\n",
    "model_name = model.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnnterp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnnsight_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     collect_activations_batched,\n\u001b[1;32m      3\u001b[0m     get_num_layers,\n\u001b[1;32m      4\u001b[0m     get_layer_output,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sample\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_word_translation_dataset, get_cloze_dataset, load_synset\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ulist\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprompt_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m translation_prompts, def_prompt, get_obj_id\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_dataset'"
     ]
    }
   ],
   "source": [
    "from nnterp.nnsight_utils import (\n",
    "    collect_activations_batched,\n",
    "    get_num_layers,\n",
    "    get_layer_output,\n",
    ")\n",
    "from random import sample\n",
    "from load_dataset import get_word_translation_dataset, get_cloze_dataset, load_synset\n",
    "from utils import ulist\n",
    "from prompt_tools import translation_prompts, def_prompt, get_obj_id\n",
    "from torch.utils.data import DataLoader\n",
    "import ast\n",
    "import itertools\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from plot_utils import plot_defs_comparison, plot_compare_setup, plot_losses_comparison\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def extract_def(generation):\n",
    "    match generation[-2], generation[-1]:\n",
    "        case '\"', \"\\n\":\n",
    "            pass\n",
    "        case _, \"\\n\":\n",
    "            end = generation.split(\"\\n\")[-2]\n",
    "            warnings.warn(f\"Last line does not end with a quote: {end}\")\n",
    "            generation = generation[:-1] + '\"\\n'\n",
    "        case _, '\"':\n",
    "            generation += \"\\n\"\n",
    "        case _:\n",
    "            end = generation.split(\"\\n\")[-1]\n",
    "            warnings.warn(f\"Last line does not end with a quote and newline: {end}\")\n",
    "            generation += '\"\\n'\n",
    "\n",
    "    last_line = generation.split(\"\\n\")[-2]\n",
    "    split = last_line.split('\"')\n",
    "    return '\"'.join(split[3:-1])\n",
    "\n",
    "\n",
    "def patched_generation(prompts, reprs, gen_batch_size):\n",
    "    pos = get_obj_id(prompts[0], tokenizer)\n",
    "    out = []\n",
    "    for i in trange(\n",
    "        0, len(prompts), gen_batch_size, desc=\"Generating patched generations\"\n",
    "    ):\n",
    "        end = min(i + gen_batch_size, len(prompts))\n",
    "        with nn_model.generate(\n",
    "            prompts[i:end],\n",
    "            max_new_tokens=50,\n",
    "            stop_strings=[\"\\n\"],\n",
    "            tokenizer=nn_model.tokenizer,\n",
    "        ):\n",
    "            if reprs is not None:\n",
    "                for layer in range(get_num_layers(nn_model)):\n",
    "                    get_layer_output(nn_model, layer)[:, pos] = reprs[i:end, layer]\n",
    "            out_model = nn_model.generator.output.tolist().save()\n",
    "        out.extend(out_model)\n",
    "    return out\n",
    "\n",
    "\n",
    "def loss_on_defs(prompts: list[str], defs: dict[str, list[str]], reprs=None):\n",
    "    \"\"\"\n",
    "    Compute the loss on the definitions\n",
    "    Args:\n",
    "        prompts: list of prompts for each concept\n",
    "        defs: dictionary of concept -> list of definitions\n",
    "        reprs: optional tensor of shape (num_prompts, num_layers, model_dim) containing the representations to patch\n",
    "    Returns:\n",
    "        dictionary of concept -> list of losses\n",
    "    \"\"\"\n",
    "    patch_pos = []\n",
    "    inputs = []\n",
    "    def_lengths = []\n",
    "    all_defs = list(itertools.chain.from_iterable(defs.values()))\n",
    "    all_prompts = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [p] * len(def_) for p, def_ in zip(prompts, defs.values())\n",
    "        )\n",
    "    )\n",
    "    repr_index = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [[i] * len(def_) for i, def_ in enumerate(defs.values())]\n",
    "        )\n",
    "    )\n",
    "    for prompt, def_ in zip(all_prompts, all_defs):\n",
    "        pos = get_obj_id(prompt, tokenizer)\n",
    "        def_ = def_ + '\"'\n",
    "        def_length = len(tokenizer.encode(def_, add_special_tokens=False))\n",
    "        def_lengths.append(def_length)\n",
    "        patch_pos.append(pos - def_length)\n",
    "        prompt_toks = tokenizer(prompt).input_ids\n",
    "        def_toks = tokenizer(def_, add_special_tokens=False).input_ids\n",
    "        input = {\n",
    "            \"input_ids\": prompt_toks + def_toks,\n",
    "            \"attention_mask\": [1] * (len(prompt_toks) + len(def_toks)),\n",
    "        }\n",
    "        inputs.append(input)\n",
    "    def_lengths = th.tensor(def_lengths)\n",
    "    def_losses = []\n",
    "    for i in trange(0, len(inputs), gen_batch_size, desc=\"Computing losses\"):\n",
    "        end = min(i + gen_batch_size, len(inputs))\n",
    "        batch_inputs = tokenizer.pad(inputs[i:end], return_tensors=\"pt\")\n",
    "        batch_patch_pos = th.tensor(patch_pos[i:end])\n",
    "        batch_repr_index = th.tensor(repr_index[i:end])\n",
    "        with nn_model.trace(batch_inputs):\n",
    "            if reprs is not None:\n",
    "                for layer in range(get_num_layers(nn_model)):\n",
    "                    get_layer_output(nn_model, layer)[\n",
    "                        th.arange(end - i), batch_patch_pos\n",
    "                    ] = reprs[batch_repr_index, layer]\n",
    "            logits = nn_model.output.logits.save()\n",
    "        # compute loss\n",
    "        mask = th.arange(logits.size(1)).unsqueeze(0) >= (\n",
    "            logits.size(1) - (def_lengths[i:end].unsqueeze(1))\n",
    "        )\n",
    "        assert mask.shape[0] == logits.shape[0] and mask.shape[1] == logits.shape[1]\n",
    "        logits = logits[:, :-1, :]\n",
    "        labels = batch_inputs.input_ids\n",
    "        labels = labels[:, 1:].to(logits.device)\n",
    "        labels[~mask[:, 1:]] = -100\n",
    "        loss = F.cross_entropy(logits.transpose(1, 2), labels, reduction=\"none\").sum(\n",
    "            dim=1\n",
    "        ) / mask[:, 1:].sum(\n",
    "            dim=1\n",
    "        ).to(logits.device)  # num_defs\n",
    "        assert loss.dim() == 1\n",
    "        def_losses.append(loss.cpu())\n",
    "    losses = th.cat(def_losses)\n",
    "    losses_dict = {}\n",
    "    prev_idx = 0\n",
    "    for concept in defs:\n",
    "        losses_dict[concept] = losses[prev_idx : prev_idx + len(defs[concept])].tolist()\n",
    "        prev_idx += len(defs[concept])\n",
    "    return losses_dict\n",
    "\n",
    "\n",
    "def patched_repr_defs(\n",
    "    lang_pairs, target_lang, path=None, num_other_for_loss=4, generate_generations=True\n",
    "):\n",
    "    lang_pairs = np.array(lang_pairs)\n",
    "    output_langs = ulist(lang_pairs[:, 1])\n",
    "    trans_dataset = get_word_translation_dataset(\n",
    "        target_lang, ulist(lang_pairs.flatten()), v2=True\n",
    "    )\n",
    "    full_def_dataset = get_cloze_dataset(\n",
    "        output_langs + [target_lang], drop_no_defs=True\n",
    "    )\n",
    "    # compute intersection between trans_dataset and def_dataset\n",
    "    common_concepts = set(trans_dataset[\"word_original\"]).intersection(\n",
    "        set(full_def_dataset[\"word_original\"])\n",
    "    )\n",
    "    if DEBUG:\n",
    "        common_concepts = sample(list(common_concepts), 8)\n",
    "        print(\"Debug mode: using only 8 common concepts\")\n",
    "    trans_dataset = trans_dataset[trans_dataset[\"word_original\"].isin(common_concepts)]\n",
    "    def_dataset = full_def_dataset[\n",
    "        full_def_dataset[\"word_original\"].isin(common_concepts)\n",
    "    ]\n",
    "    common_concepts = def_dataset[\"word_original\"].tolist()\n",
    "    assert len(trans_dataset) == len(def_dataset)\n",
    "    print(f\"Found {len(common_concepts)} common concepts\")\n",
    "    trans_source_prompts = np.array(\n",
    "        [\n",
    "            translation_prompts(\n",
    "                trans_dataset,\n",
    "                tokenizer,\n",
    "                input_lang,\n",
    "                output_lang,\n",
    "                n=num_few_shot,\n",
    "                cut_at_obj=True,\n",
    "            )\n",
    "            for input_lang, output_lang in lang_pairs\n",
    "        ]\n",
    "    )\n",
    "    trans_source_prompts_str = list(\n",
    "        chain.from_iterable(\n",
    "            [p.prompt for p in prompts] for prompts in trans_source_prompts\n",
    "        )\n",
    "    )\n",
    "    def_source_prompts = [\n",
    "        def_prompt(\n",
    "            def_dataset,\n",
    "            tokenizer,\n",
    "            output_lang,\n",
    "            n=num_few_shot,\n",
    "            use_word_to_def=True,\n",
    "            cut_at_obj=True,\n",
    "        )\n",
    "        for output_lang in output_langs\n",
    "    ]\n",
    "    def_source_prompts_str = list(\n",
    "        chain.from_iterable(\n",
    "            [p.prompt for p in prompts] for prompts in def_source_prompts\n",
    "        )\n",
    "    )\n",
    "\n",
    "    gt_defs, _ = ground_truth_defs(target_lang, common_concepts)\n",
    "    trans_activations = (\n",
    "        collect_activations_batched(\n",
    "            nn_model,\n",
    "            list(trans_source_prompts_str),\n",
    "            batch_size=batch_size,\n",
    "            tqdm=tqdm,\n",
    "        )\n",
    "        .transpose(0, 1)\n",
    "        .reshape(len(lang_pairs), len(trans_dataset), get_num_layers(nn_model), -1)\n",
    "    )  # num_langs, num_concepts, num_layers, model_dim\n",
    "    trans_mean_reprs = trans_activations.mean(\n",
    "        dim=0\n",
    "    )  # num_concepts, num_layers, model_dim\n",
    "    trans_single_reprs = trans_activations[0]  # num_concepts, num_layers, model_dim\n",
    "    def_activations = (\n",
    "        collect_activations_batched(\n",
    "            nn_model,\n",
    "            def_source_prompts_str,\n",
    "            batch_size=batch_size,\n",
    "            tqdm=tqdm,\n",
    "        )\n",
    "        .transpose(0, 1)\n",
    "        .reshape(len(output_langs), len(def_dataset), get_num_layers(nn_model), -1)\n",
    "    )  # num_langs, num_concepts, num_layers, model_dim\n",
    "    def_mean_reprs = def_activations.mean(dim=0)  # num_concepts, num_layers, model_dim\n",
    "    def_single_reprs = def_activations[0]  # num_concepts, num_layers, model_dim\n",
    "    target_prompts = []\n",
    "    for concept in common_concepts:\n",
    "        safe_df = full_def_dataset[full_def_dataset[\"word_original\"] != concept]\n",
    "        safe_prompt = sample(\n",
    "            def_prompt(\n",
    "                safe_df,\n",
    "                tokenizer,\n",
    "                target_lang,\n",
    "                n=num_few_shot,\n",
    "                use_word_to_def=True,\n",
    "                cut_at_obj=False,\n",
    "            ),\n",
    "            1,\n",
    "        )[0]\n",
    "        target_prompts.append(safe_prompt)\n",
    "    target_prompts_str = [p.prompt for p in target_prompts]\n",
    "    baseline_target_prompts_str = [\n",
    "        p.prompt\n",
    "        for p in def_prompt(\n",
    "            def_dataset,\n",
    "            tokenizer,\n",
    "            target_lang,\n",
    "            n=num_few_shot,\n",
    "            use_word_to_def=True,\n",
    "            cut_at_obj=False,\n",
    "        )\n",
    "    ]\n",
    "    other_concept_defs = [{} for _ in range(num_other_for_loss)]\n",
    "    for i, concept in enumerate(common_concepts):\n",
    "        other_concepts = th.randint(0, len(common_concepts) - 1, (num_other_for_loss,))\n",
    "        other_concepts[other_concepts >= i] += 1\n",
    "        for j, other_concept in enumerate(other_concepts):\n",
    "            other_concept_defs[j][concept] = gt_defs[common_concepts[other_concept]]\n",
    "    generations = {}\n",
    "    losses = {}\n",
    "    other_concepts_losses = [{} for _ in range(num_other_for_loss)]\n",
    "\n",
    "    for repr_type, reprs in [\n",
    "        (\"from def\", def_mean_reprs),\n",
    "        (\"from single def\", def_single_reprs),\n",
    "        (\"from trans\", trans_mean_reprs),\n",
    "        (\"from single trans\", trans_single_reprs),\n",
    "        (\"prompting\", None),\n",
    "    ]:\n",
    "        tgt_prompts = target_prompts_str\n",
    "        if repr_type == \"prompting\":\n",
    "            tgt_prompts = baseline_target_prompts_str\n",
    "        if generate_generations:\n",
    "            output = patched_generation(tgt_prompts, reprs, gen_batch_size)\n",
    "            generations[repr_type] = tokenizer.batch_decode(\n",
    "                output, skip_special_tokens=True\n",
    "            )\n",
    "        losses[repr_type] = loss_on_defs(tgt_prompts, gt_defs, reprs)\n",
    "        for i, other_defs in enumerate(other_concept_defs):\n",
    "            other_concepts_losses[i][repr_type] = loss_on_defs(\n",
    "                tgt_prompts, other_defs, reprs\n",
    "            )\n",
    "\n",
    "    json_file = path / (\"patched_generations_and_losses.json\")\n",
    "    defs = defaultdict(dict)\n",
    "    generations_dict = defaultdict(dict)\n",
    "    losses_dict = defaultdict(lambda: defaultdict(dict))\n",
    "    for repr_type in [\n",
    "        \"from def\",\n",
    "        \"from single def\",\n",
    "        \"from trans\",\n",
    "        \"from single trans\",\n",
    "        \"prompting\",\n",
    "    ]:\n",
    "        for i, concept in enumerate(common_concepts):\n",
    "            if generate_generations:\n",
    "                gen = generations[repr_type][i]\n",
    "                defs[concept][repr_type] = extract_def(gen)\n",
    "                generations_dict[concept][repr_type] = gen\n",
    "            losses_dict[concept][repr_type][\"other\"] = [\n",
    "                ocl[repr_type][concept] for ocl in other_concepts_losses\n",
    "            ]\n",
    "            losses_dict[concept][repr_type][\"normal\"] = losses[repr_type][concept]\n",
    "    json_dic = {\n",
    "        \"defs\": defs,\n",
    "        \"generations\": generations_dict,\n",
    "        \"losses\": losses_dict,\n",
    "    }\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "    return defs, losses_dict, other_concept_defs\n",
    "\n",
    "\n",
    "def generate_generations(prompts, concepts):\n",
    "    str_prompts = [p.prompt for p in prompts]\n",
    "    dataloader = DataLoader(str_prompts, batch_size=batch_size)\n",
    "    generations = []\n",
    "    for batch in dataloader:\n",
    "        with nn_model.generate(\n",
    "            batch, max_new_tokens=50, stop_strings=[\"\\n\"], tokenizer=nn_model.tokenizer\n",
    "        ):\n",
    "            out = nn_model.generator.output.tolist().save()\n",
    "        generations.extend(out)\n",
    "    generations = tokenizer.batch_decode(generations, skip_special_tokens=True)\n",
    "    generations = {\n",
    "        concept: \"...\\n\" + \"\\n\".join(generation.split(\"\\n\")[-3:-1])\n",
    "        for concept, generation in zip(concepts, generations)\n",
    "    }\n",
    "    defs = {\n",
    "        concept: extract_def(generation) for concept, generation in generations.items()\n",
    "    }\n",
    "    return {\"defs\": defs, \"generations\": generations}\n",
    "\n",
    "\n",
    "def word_patching_defs(\n",
    "    source_langs, target_lang, concepts, gt_defs, other_concept_defs, exp_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a definition in target_lang from the source_lang concept\n",
    "    \"\"\"\n",
    "    df = get_cloze_dataset(source_langs + [target_lang], drop_no_defs=True)\n",
    "    df = df[df[\"word_original\"].isin(concepts)]\n",
    "    assert len(df) == len(concepts)\n",
    "    prompts = []\n",
    "    for concept in concepts:\n",
    "        safe_df = df[df[\"word_original\"] != concept]\n",
    "        source_lang = sample(source_langs, 1)[0]\n",
    "        # add a new row with word_original = concept, senses_{target_lang} = senses_{source_lang}\n",
    "        original_row = df[df[\"word_original\"] == concept].iloc[0]\n",
    "        new_row = original_row.copy()\n",
    "        new_row[f\"senses_{target_lang}\"] = original_row[f\"senses_{source_lang}\"]\n",
    "        safe_df = pd.concat([safe_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        prompt = def_prompt(\n",
    "            safe_df,\n",
    "            tokenizer,\n",
    "            target_lang,\n",
    "            n=num_few_shot,\n",
    "            use_word_to_def=True,\n",
    "            concepts=[concept],\n",
    "        )\n",
    "        prompts.append(prompt[0])\n",
    "    result_dict = generate_generations(prompts, concepts)\n",
    "    losses = {\n",
    "        concept: {\"normal\": loss, \"other\": []}\n",
    "        for concept, loss in loss_on_defs([p.prompt for p in prompts], gt_defs).items()\n",
    "    }\n",
    "    other_concepts_losses = [\n",
    "        loss_on_defs([p.prompt for p in prompts], other_defs)\n",
    "        for other_defs in other_concept_defs\n",
    "    ]\n",
    "    for concept in concepts:\n",
    "        for other_losses in other_concepts_losses:\n",
    "            losses[concept][\"other\"].append(other_losses[concept])\n",
    "    json_file = exp_path / (\"word_patching_defs.json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(result_dict, f, indent=4)\n",
    "    return result_dict[\"defs\"], losses\n",
    "\n",
    "\n",
    "# def gen_baseline_defs(lang, concepts, exp_path):\n",
    "#     df = get_cloze_dataset(lang, drop_no_defs=True)\n",
    "#     prompts = def_prompt(\n",
    "#         df, tokenizer, lang, n=num_few_shot, use_word_to_def=True, concepts=concepts\n",
    "#     )\n",
    "#     json_dic = generate_generations(prompts, concepts)\n",
    "#     json_file = exp_path / (exp_id + \"baseline_defs.json\")\n",
    "#     with open(json_file, \"w\") as f:\n",
    "#         json.dump(json_dic, f, indent=4)\n",
    "#     return json_dic[\"defs\"]\n",
    "\n",
    "\n",
    "def ground_truth_defs(lang, concept):\n",
    "    df = load_synset(lang)\n",
    "    gt_defs = {\n",
    "        concept: ulist(\n",
    "            ast.literal_eval(\n",
    "                df[df[\"word_original\"] == concept][\"definitions\"].tolist()[0]\n",
    "            )\n",
    "        )\n",
    "        for concept in concept\n",
    "    }\n",
    "    tgt_words = {\n",
    "        concept: ast.literal_eval(\n",
    "            df[df[\"word_original\"] == concept][\"senses\"].tolist()[0]\n",
    "        )[0]\n",
    "        for concept in concept\n",
    "    }\n",
    "    return gt_defs, tgt_words\n",
    "\n",
    "\n",
    "def generate_embeddings(prompts):\n",
    "    if isinstance(prompts, dict):\n",
    "        prompts = list(itertools.chain.from_iterable(prompts.values()))\n",
    "    embeddings = embeddings_model.encode(\n",
    "        prompts, batch_size=emb_batch_size, convert_to_tensor=True\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def compare_defs(defs, gt_defs_embeddings):\n",
    "    \"\"\"\n",
    "    Compare the definitions generated by the model to the ground truth definitions.\n",
    "\n",
    "    Args:\n",
    "        defs: a dictionary of concept -> list of definitions\n",
    "        gt_defs_embeddings: a tensor of shape (num_concepts, num_defs, embedding_dim) containing the embeddings of the ground truth definitions\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    all_defs = list(itertools.chain.from_iterable(defs.values()))\n",
    "    all_defs_embeddings = generate_embeddings(all_defs)\n",
    "    similarities = embeddings_model.similarity(all_defs_embeddings, gt_defs_embeddings)\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def plot_results(result_dict, method_names, title_suffix, path):\n",
    "    # === Plotting ===\n",
    "    extra_path = path / \"extras\"\n",
    "    extra_path.mkdir(exist_ok=True)\n",
    "    for method, title in method_names.items():\n",
    "        plot_defs_comparison(result_dict, method, title, extra_path, show=False)\n",
    "    plot_compare_setup(result_dict, path, title_suffix.replace(\"<br>\", \"\"), exp_id)\n",
    "\n",
    "\n",
    "def experiment(lang_pairs, target_lang):\n",
    "    pref = \"_\".join(\"-\".join(ls) for ls in lang_pairs)\n",
    "    title_suffix = (\n",
    "        \"<br>(\" + \", \".join([t for s, t in lang_pairs]) + \") -> \" + target_lang\n",
    "    )\n",
    "    method_names = {\n",
    "        \"from trans\": \"Patching mean representation from translations\" + title_suffix,\n",
    "        \"from def\": \"Patching mean representation from definitions\" + title_suffix,\n",
    "        \"from single trans\": \"Patching single representation from translations\"\n",
    "        + title_suffix,\n",
    "        \"from single def\": \"Patching single representation from definitions\"\n",
    "        + title_suffix,\n",
    "        \"word patch\": \"Word patching\" + title_suffix,\n",
    "        \"prompting\": \"Vanilla prompting\" + f\" {target_lang}\",\n",
    "        \"repeat word\": \"Repeat word\" + f\" {target_lang}\",\n",
    "        \"rnd gt\": \"Random GT definition\" + f\" {target_lang}\",\n",
    "    }\n",
    "    methods = list(method_names.keys())\n",
    "    path = Path(\"results\") / model_name / exp_name / f\"{pref}-{target_lang}\" / exp_id\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    source_output_langs = ulist([p[1] for p in lang_pairs])\n",
    "    # === Generate Definitions ===\n",
    "    defs, losses, other_concept_defs = patched_repr_defs(lang_pairs, target_lang, path)\n",
    "    concepts = defs.keys()\n",
    "    gt_defs, tgt_words = ground_truth_defs(target_lang, concepts)\n",
    "    token_patching_defs, word_patching_losses = word_patching_defs(\n",
    "        source_output_langs, target_lang, concepts, gt_defs, other_concept_defs, path\n",
    "    )\n",
    "    for w in losses:\n",
    "        losses[w][\"word patch\"] = word_patching_losses[w]\n",
    "    with open(path / \"losses.json\", \"w\") as f:\n",
    "        json.dump(losses, f, indent=4)\n",
    "    dict_factory_losses = lambda: {m: defaultdict(dict) for m in methods[:-2]}\n",
    "    losses_dict = defaultdict(dict_factory_losses)\n",
    "    for w in losses:\n",
    "        for setup in losses[w]:\n",
    "            max_loss = max(losses[w][setup][\"normal\"])\n",
    "            losses_dict[w][setup][\"max loss\"] = max_loss\n",
    "            losses_dict[w][setup][\"mean loss\"] = np.mean(losses[w][setup][\"normal\"])\n",
    "            losses_dict[w][setup][\"min loss\"] = np.min(losses[w][setup][\"normal\"])\n",
    "            all_losses = list(chain.from_iterable(losses[w][setup][\"other\"]))\n",
    "            losses_dict[w][setup][\"mean loss with others\"] = np.mean(all_losses)\n",
    "            losses_dict[w][setup][\"mean max loss with others\"] = np.mean(\n",
    "                [max(other_losses) for other_losses in losses[w][setup][\"other\"]]\n",
    "            )\n",
    "            losses_dict[w][setup][\"mean min loss with others\"] = np.mean(\n",
    "                [min(other_losses) for other_losses in losses[w][setup][\"other\"]]\n",
    "            )\n",
    "    with open(path / \"losses_stats.json\", \"w\") as f:\n",
    "        json.dump(losses_dict, f, indent=4)\n",
    "    plot_losses_comparison(losses_dict, path, title_suffix)\n",
    "\n",
    "    for w_defs in gt_defs.values():\n",
    "        shuffle(w_defs)\n",
    "    all_defs = {\n",
    "        concept: [\n",
    "            defs[concept][\"from trans\"],\n",
    "            defs[concept][\"from def\"],\n",
    "            defs[concept][\"from single trans\"],\n",
    "            defs[concept][\"from single def\"],\n",
    "            token_patching_defs[concept],\n",
    "            defs[concept][\"prompting\"],\n",
    "            tgt_words[concept],\n",
    "            gt_defs[concept][0],\n",
    "        ]\n",
    "        for concept in defs\n",
    "    }\n",
    "\n",
    "    # === Generate Embeddings ===\n",
    "    gt_defs_embeddings = generate_embeddings(gt_defs)\n",
    "    all_idx = []\n",
    "    gt_embeddings_dict = {}\n",
    "    prev_idx = 0\n",
    "    for concept, defs_list in gt_defs.items():\n",
    "        gt_embeddings_dict[concept] = gt_defs_embeddings[\n",
    "            prev_idx : prev_idx + len(defs_list)\n",
    "        ]\n",
    "        prev_idx += len(defs_list)\n",
    "        all_idx.append(prev_idx)\n",
    "    all_idx.append(0)  # for the first concept\n",
    "\n",
    "    mean_embeddings = th.stack([emb.mean(dim=0) for emb in gt_embeddings_dict.values()])\n",
    "    mean_embeddings_wo_fst = th.stack(\n",
    "        [\n",
    "            emb[1:].mean(dim=0) if len(emb) > 1 else emb.mean(dim=0)\n",
    "            for emb in gt_embeddings_dict.values()\n",
    "        ]\n",
    "    )\n",
    "    assert (\n",
    "        mean_embeddings.shape[0] == len(defs)\n",
    "        and mean_embeddings.shape[1] == gt_defs_embeddings.shape[1]\n",
    "    ), f\"Shape mismatch: mean_embeddings.shape={mean_embeddings.shape} != gt_defs_embeddings.shape={gt_defs_embeddings.shape}, len(defs)={len(defs)}\"\n",
    "    similarities = compare_defs(all_defs, gt_defs_embeddings)\n",
    "    similarities_mean = compare_defs(all_defs, mean_embeddings)\n",
    "    similarities_mean_wo_fst = compare_defs(all_defs, mean_embeddings_wo_fst)\n",
    "\n",
    "    dict_factory = lambda: {m: {} for m in methods}\n",
    "\n",
    "    result_dict = defaultdict(dict_factory)\n",
    "    for i, concept in enumerate(defs):\n",
    "        for j, method in enumerate(methods):\n",
    "            sim_w_mean = similarities_mean[len(methods) * i + j][i]\n",
    "            sim_w_mean_wo_fst = similarities_mean_wo_fst[len(methods) * i + j][i]\n",
    "            start_idx = all_idx[i - 1]\n",
    "            if method == \"rnd gt\":\n",
    "                start_idx += 1  # skip self\n",
    "            sims = similarities[len(methods) * i + j][start_idx : all_idx[i]]\n",
    "            other_sims = th.cat(\n",
    "                [\n",
    "                    similarities[len(methods) * i + j][0 : all_idx[i - 1]],\n",
    "                    similarities[len(methods) * i + j][all_idx[i] :],\n",
    "                ]\n",
    "            )\n",
    "            max_sim_with_others = []\n",
    "            for k in range(len(defs)):\n",
    "                if k == i:\n",
    "                    continue\n",
    "                max_sim_with_others.append(\n",
    "                    similarities[len(methods) * i + j][all_idx[k - 1] : all_idx[k]]\n",
    "                    .max()\n",
    "                    .item()\n",
    "                )\n",
    "            result_dict[concept][method][\n",
    "                \"mean sim with others\"\n",
    "            ] = other_sims.mean().item()\n",
    "            result_dict[concept][method][\"mean max sim with others\"] = np.mean(\n",
    "                max_sim_with_others\n",
    "            )\n",
    "            if method == \"rnd gt\" and len(gt_defs[concept]) == 1:\n",
    "                # doesn't make sense to compare to itself\n",
    "                result_dict[concept][method][\"sim w mean\"] = None\n",
    "                result_dict[concept][method][\"sim w mean fst\"] = None\n",
    "                result_dict[concept][method][\"mean sim\"] = None\n",
    "                result_dict[concept][method][\"max sim\"] = None\n",
    "            else:\n",
    "                result_dict[concept][method][\"sim w mean\"] = sim_w_mean.item()\n",
    "                result_dict[concept][method][\n",
    "                    \"sim w mean fst\"\n",
    "                ] = sim_w_mean_wo_fst.item()\n",
    "                result_dict[concept][method][\"mean sim\"] = sims.mean().item()\n",
    "                result_dict[concept][method][\"max sim\"] = sims.max().item()\n",
    "\n",
    "    json_file = path / (\"defs_comparison.json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(result_dict, f, indent=4)\n",
    "    plot_results(result_dict, method_names, title_suffix, path)\n",
    "    return result_dict, method_names, title_suffix, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 common concepts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fd097f5ab3413f896bd9abbaac348d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a4932268024960a667d923bec3ebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/logging/__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/logging/__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2686292/2574892469.py\", line 18, in <module>\n",
      "    plot_args = experiment(*pargs)\n",
      "  File \"/tmp/ipykernel_2686292/2592853572.py\", line 419, in experiment\n",
      "    defs, losses = patched_repr_defs(lang_pairs, target_lang, path)\n",
      "  File \"/tmp/ipykernel_2686292/2592853572.py\", line 202, in patched_repr_defs\n",
      "    collect_activations_batched(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnterp/nnsight_utils.py\", line 391, in collect_activations_batched\n",
      "    acts_batch = collect_activations(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnterp/nnsight_utils.py\", line 277, in collect_activations\n",
      "    with context:\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/intervention/contexts/interleaving.py\", line 96, in __exit__\n",
      "    super().__exit__(exc_type, exc_val, exc_tb)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/tracing/contexts/tracer.py\", line 25, in __exit__\n",
      "    return super().__exit__(exc_type, exc_val, exc_tb)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/tracing/contexts/base.py\", line 82, in __exit__\n",
      "    self.backend(graph)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/tracing/backends/base.py\", line 24, in __call__\n",
      "    graph.nodes[-1].execute()\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/tracing/graph/node.py\", line 289, in execute\n",
      "    self.target.execute(self)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/intervention/contexts/interleaving.py\", line 161, in execute\n",
      "    graph.model.interleave(interleaver, *invoker_args, fn=method,**kwargs, **invoker_kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/modeling/mixins/meta.py\", line 49, in interleave\n",
      "    return super().interleave(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/intervention/base.py\", line 335, in interleave\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/nnsight/modeling/language.py\", line 287, in _execute\n",
      "    return self._model(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1603, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/accelerate/hooks.py\", line 169, in new_forward\n",
      "    output = module._old_forward(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py\", line 1027, in forward\n",
      "    outputs = self.model(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1603, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py\", line 827, in forward\n",
      "    logger.warning_once(\n",
      "  File \"/dlabscratch1/cdumas/thinking-lang/.conda/lib/python3.11/site-packages/transformers/utils/logging.py\", line 328, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: \"You are calling the model with `use_cache=True` but didn't pass `past_key_values` while not training. \"\n",
      "Arguments: ('If you want to compute with cache, make sure to pass an instance of `HybridCache`. An empty `HybridCache` instance will be created for this call. See for more: (https://huggingface.co/docs/transformers/main/en/internal/generation_utils#transformers.HybridCache)',)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7572a17c44fa4d6cb6f3528d059e24aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24b98e5cd8a4bbaa2471351adbec944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc85f5d7ba44a8f91cbc99eadd77b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689, 117095, 235281],\n",
      "        [     2, 235281,  23427,  ...,    573,   9561,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  19071,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1809,   2377, 235281],\n",
      "        [     0,      0,      0,  ...,   3818,  13120, 235281],\n",
      "        [     0,      0,      0,  ...,   6792,   9561,  71982]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 4 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    974,   2550, 235281],\n",
      "        [     0,      0,      0,  ...,   1809,   2377, 235281],\n",
      "        [     0,      0,      0,  ...,   3818,  13120, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      2,  ...,    573,   8218, 235281],\n",
      "        [     2, 235281,   1785,  ..., 170540,  44533,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  36789,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 205])\n",
      "logits: torch.Size([8, 205, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 8 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3818,   2857,   1464],\n",
      "        [     0,      0,      2,  ...,    573,   8218, 235281],\n",
      "        [     2, 235281,   1785,  ..., 170540,  44533,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,   1785,  ...,  16010,  36239,   1464],\n",
      "        [     0,      2, 235281,  ...,   1959,  27751,   1464],\n",
      "        [     0,      0,      0,  ...,   3131,    665, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 205])\n",
      "logits: torch.Size([8, 205, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 12 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,  31029, 235281],\n",
      "        [     2, 235281,   1785,  ...,  16010,  36239,   1464],\n",
      "        [     0,      2, 235281,  ...,   1959,  27751,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   4937,   5171,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   4412, 235281],\n",
      "        [     0,      0,      0,  ...,   5097,  44891,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 205])\n",
      "logits: torch.Size([8, 205, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 16 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  17848,  ...,   2691,    665,   1464],\n",
      "        [     0,      0,      0,  ...,   4937,   5171,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   4412, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 184644,   5356,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  21753, 235281],\n",
      "        [     0,      0,      0,  ...,    689,   9451,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 20 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    671,   2951,   1464],\n",
      "        [     0,      0,      0,  ..., 184644,   5356,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  21753, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  14649, 235281],\n",
      "        [     0,      0,      0,  ...,    689,  18870,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  56662,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 180])\n",
      "logits: torch.Size([8, 180, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 24 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,  14098,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  14649, 235281],\n",
      "        [     0,      0,      0,  ...,    689,  18870,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   7165, 235281],\n",
      "        [     2, 235281, 110184,  ...,    604,  48755,   1464],\n",
      "        [     0,      0,      0,  ...,  11406,  18167, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 28 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    575,  15533,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   7165, 235281],\n",
      "        [     0,      0,      0,  ...,    604,  48755,   1464],\n",
      "        ...,\n",
      "        [     0,      2, 235281,  ...,    578, 118691,   1464],\n",
      "        [     2, 235281, 110184,  ...,   5877,   5097,   1464],\n",
      "        [     0,      0,      0,  ..., 157671,   9364,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 206])\n",
      "logits: torch.Size([8, 206, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 32 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  31804,   2036, 235281],\n",
      "        [     0,      2, 235281,  ...,    578, 118691,   1464],\n",
      "        [     2, 235281, 110184,  ...,   5877,   5097,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    664,  15557,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   5063, 235281],\n",
      "        [     0,      0,      0,  ...,   3515,  27290,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 206])\n",
      "logits: torch.Size([8, 206, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 36 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281, 110184,  ...,    476,   3733,   1464],\n",
      "        [     0,      0,      0,  ...,    664,  15557,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   5063, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1913, 235265,    664],\n",
      "        [     0,      0,      0,  ...,    689,   8205,   1464],\n",
      "        [     0,      0,      0,  ...,   7382,  86235,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 40 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1162,   2187,   1464],\n",
      "        [     0,      0,      0,  ...,   1913, 235265,    664],\n",
      "        [     0,      0,      0,  ...,    689,   8205,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3515,   1855,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  13864, 235281],\n",
      "        [     0,      0,      0,  ...,  73308,  25362,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 185])\n",
      "logits: torch.Size([8, 185, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 44 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,    845,  ...,    483,   6137,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   1855,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  13864, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  24966,  21069, 235281],\n",
      "        [     0,      0,      0,  ...,    573,  13864, 235281],\n",
      "        [     0,      0,      0,  ...,    573,  13864,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 185])\n",
      "logits: torch.Size([8, 185, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 48 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  73308,  25362, 235281],\n",
      "        [     0,      0,      0,  ...,  24966,  21069, 235281],\n",
      "        [     0,      0,      0,  ...,    573,  13864, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  13864,   1464],\n",
      "        [     2, 235281,   5583,  ...,  16800,  17638, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 52 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  11441,    665,   1464],\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  13864,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   2301,   9113,   1464],\n",
      "        [     0,      0,      2,  ...,    476,   3587,   1464],\n",
      "        [     0,      0,      0,  ...,    604,  23457,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 201])\n",
      "logits: torch.Size([8, 201, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 56 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,   5583,  ...,   1156,   9841,   1464],\n",
      "        [     0,      0,      0,  ...,   2301,   9113,   1464],\n",
      "        [     0,      0,      2,  ...,    476,   3587,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    577,   6284, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  10228,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  10228,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 201])\n",
      "logits: torch.Size([8, 201, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 60 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      2,  ...,    664, 201359,   1464],\n",
      "        [     0,      0,      0,  ...,    577,   6284, 235281],\n",
      "        [     2, 235281,  20742,  ...,    578,  10228,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   6284,    611,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   6284,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  16241,   1464]]), 'attention_mask': tensor([[0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 185])\n",
      "logits: torch.Size([8, 185, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 64 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,  10228, 235281],\n",
      "        [     0,      0,      0,  ...,   6284,    611,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   6284,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  14556,  ...,  17839,  17195,   1464],\n",
      "        [     0,      0,      0,  ...,  62912,  35312,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  31029, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 68 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  61689,   6202, 235281],\n",
      "        [     0,      0,      0,  ...,  17839,  17195,   1464],\n",
      "        [     0,      0,      0,  ...,  62912,  35312,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  14556,  ...,    578,  17195,   1464],\n",
      "        [     0,      0,      0,  ...,    664, 192365,   1464],\n",
      "        [     0,      0,      0,  ...,   1185,  22121, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 201])\n",
      "logits: torch.Size([8, 201, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 72 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   9615,  18110,   1464],\n",
      "        [     2, 235281,  14556,  ...,    578,  17195,   1464],\n",
      "        [     0,      0,      0,  ...,    664, 192365,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    577,  15878, 235281],\n",
      "        [     0,      0,      0,  ...,   1185,  22121,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   4547,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 201])\n",
      "logits: torch.Size([8, 201, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 76 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 235256,  16277,   1464],\n",
      "        [     0,      0,      0,  ...,    577,  15878, 235281],\n",
      "        [     0,      0,      0,  ...,   1185,  22121,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    685,  18751, 235281],\n",
      "        [     2, 235281,  77455,  ...,  30322,  43974,   1464],\n",
      "        [     0,      0,      0,  ..., 235269, 157933,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 217])\n",
      "logits: torch.Size([8, 217, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 80 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 235256,   8566,   1464],\n",
      "        [     0,      0,      0,  ...,    685,  18751, 235281],\n",
      "        [     2, 235281,  77455,  ...,  30322,  43974,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476, 100903, 235281],\n",
      "        [     0,      0,      0,  ...,    577,   8960,   1464],\n",
      "        [     0,      0,      0,  ...,  32816,  12776,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 217])\n",
      "logits: torch.Size([8, 217, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 84 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 157933,   8205,   1464],\n",
      "        [     0,      0,      0,  ...,    476, 100903, 235281],\n",
      "        [     0,      0,      0,  ...,    577,   8960,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1386,  14125,   1464],\n",
      "        [     0,      0,      0,  ...,   1386,  14125,   1464],\n",
      "        [     0,      0,      0,  ...,   1386,  14125, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 88 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1009,   4391, 235281],\n",
      "        [     0,      0,      2,  ...,   1386,  14125,   1464],\n",
      "        [     0,      0,      0,  ...,   1386,  14125,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3666,   1411,   1464],\n",
      "        [     2, 235281,  11539,  ...,  12134,  36894,   1464],\n",
      "        [     0,      0,      0,  ...,   3724,   6187,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 92 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  12134,  36894,   1464],\n",
      "        [     0,      0,      0,  ...,   3666,   1411,   1464],\n",
      "        [     2, 235281,  11539,  ...,  12134,  36894,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   6383,  26321,   1464],\n",
      "        [     0,      0,      0,  ...,  37277,   2395,   1464],\n",
      "        [     0,      0,      0,  ...,   2003,  19033, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 96 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    611,   2003, 235281],\n",
      "        [     2, 235281,   8619,  ...,   6383,  26321,   1464],\n",
      "        [     0,      0,      0,  ...,  37277,   2395,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    731,   6785,   1464],\n",
      "        [     0,      0,      0,  ...,  11586,  18038,   1464],\n",
      "        [     0,      0,      0,  ...,    576, 173940, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 166])\n",
      "logits: torch.Size([8, 166, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 100 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1163,   2003,   1464],\n",
      "        [     2, 235281,   8619,  ...,    731,   6785,   1464],\n",
      "        [     0,      0,      0,  ...,  11586,  18038,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576, 173940,   1464],\n",
      "        [     0,      0,      0,  ...,    576, 173940, 235281],\n",
      "        [     0,      0,      0,  ...,   1546, 173940,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 160])\n",
      "logits: torch.Size([8, 160, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 104 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 157933,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,    576, 173940,   1464],\n",
      "        [     0,      0,      0,  ...,    576, 173940, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   6406,   3584,  17846],\n",
      "        [     0,      0,      0,  ...,    476,   3098,   1464],\n",
      "        [     2, 235281, 117809,  ...,    974,   2857,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 108 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664,   6168,   1464],\n",
      "        [     0,      0,      0,  ...,   6406,   3584,  17846],\n",
      "        [     0,      0,      0,  ...,    476,   3098,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   9934,   1736, 235281],\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     2, 235281, 117809,  ..., 235290,   2545,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 197])\n",
      "logits: torch.Size([8, 197, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 112 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3661,   2113, 235281],\n",
      "        [     0,      0,      0,  ...,   9934,   1736, 235281],\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  60313,  53698,   1464],\n",
      "        [     0,      0,      0,  ..., 103373,   2893,   1464],\n",
      "        [     0,      0,      0,  ..., 157172,  11254, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 197])\n",
      "logits: torch.Size([8, 197, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 116 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  68131,  ...,    689,  83264, 235281],\n",
      "        [     0,      0,      0,  ...,  60313,  53698,   1464],\n",
      "        [     0,      0,      0,  ..., 103373,   2893,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   8576,  53698,   1464],\n",
      "        [     0,      0,      0,  ...,    664,   6813,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  23729, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 190])\n",
      "logits: torch.Size([8, 190, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 120 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   8576,  53698,   1464],\n",
      "        [     2, 235281,  68131,  ...,   8576,  53698,   1464],\n",
      "        [     0,      0,      0,  ...,    664,   6813,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  37559,  10012,   1464],\n",
      "        [     0,      0,      0,  ..., 235290,    927, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   3741,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 182])\n",
      "logits: torch.Size([8, 182, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 124 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1277,  14010,   1464],\n",
      "        [     0,      0,      0,  ...,  37559,  10012,   1464],\n",
      "        [     0,      0,      0,  ..., 235290,    927, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  14051,   5100,   1464],\n",
      "        [     0,      0,      0,  ...,   9202,   1552, 235281],\n",
      "        [     2, 235281,  39074,  ...,   9202,   3515,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 167])\n",
      "logits: torch.Size([8, 167, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 128 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  14051,   5100,   1464],\n",
      "        [     0,      0,      0,  ...,  14051,   5100,   1464],\n",
      "        [     0,      0,      0,  ...,   9202,   1552, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  11481,   1464],\n",
      "        [     0,      0,      0,  ...,   9202,   3515, 235281],\n",
      "        [     2, 235281,  39074,  ...,    689,  47913,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 170])\n",
      "logits: torch.Size([8, 170, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 132 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3486,    916,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  11481,   1464],\n",
      "        [     0,      0,      0,  ...,   9202,   3515, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   3519, 235281],\n",
      "        [     2, 235281,  44515,  ...,    689,   1879,   1464],\n",
      "        [     0,      0,      0,  ...,   1582,  32355,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 221])\n",
      "logits: torch.Size([8, 221, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 136 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,   3519, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   3519, 235281],\n",
      "        [     2, 235281,  44515,  ...,    689,   1879,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3515,   3403,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  53317,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  38026, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 221])\n",
      "logits: torch.Size([8, 221, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 140 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    578,  38026,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   3403,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  53317,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,   1879, 235281],\n",
      "        [     2, 235281,  44515,  ...,    578,  53317,   1464],\n",
      "        [     0,      0,      0,  ...,    604,   2775,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 209])\n",
      "logits: torch.Size([8, 209, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 144 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3515,  26124, 235281],\n",
      "        [     0,      0,      0,  ...,    689,   1879, 235281],\n",
      "        [     0,      0,      2,  ...,    578,  53317,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  44515,  ...,    708,   3482,   1464],\n",
      "        [     0,      0,      0,  ...,   8383,  16089,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  16121,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 211])\n",
      "logits: torch.Size([8, 211, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 148 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1997,   9398,   1464],\n",
      "        [     2, 235281,  44515,  ...,    708,   3482,   1464],\n",
      "        [     0,      0,      0,  ...,   8383,  16089,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   8692, 235281],\n",
      "        [     0,      0,      0,  ...,   8096,   1812,   1464],\n",
      "        [     0,      0,      0,  ...,  96223,   8252,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 211])\n",
      "logits: torch.Size([8, 211, 256000])\n",
      "reprs: torch.Size([8, 26, 2304])\n",
      "i: 152 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  44515,  ...,    671,   3811,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   8692, 235281],\n",
      "        [     0,      0,      0,  ...,   8096,   1812,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   8692,   1464],\n",
      "        [     0,      0,      0,  ...,  16801,   6064,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   8692,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 202])\n",
      "logits: torch.Size([8, 202, 256000])\n",
      "reprs: torch.Size([4, 26, 2304])\n",
      "i: 156 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  96223,   8252, 235281],\n",
      "        [     0,      0,      0,  ...,    476,   8692,   1464],\n",
      "        [     0,      0,      0,  ...,  16801,   6064,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      2,  ...,   6269,   5188,   1464],\n",
      "        [     0,      0,      0,  ...,    578,   3545,   1464],\n",
      "        [     0,      0,      0,  ...,    578,   3545,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 160 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      2,  ...,   1024,   4815, 235281],\n",
      "        [     0,      0,      0,  ...,   6269,   5188,   1464],\n",
      "        [     0,      0,      0,  ...,    578,   3545,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  13712,   1464],\n",
      "        [     2, 235281,  23144,  ...,    576,   4584,   1464],\n",
      "        [     0,      0,      0,  ...,    664,  18086,   1464]]), 'attention_mask': tensor([[0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 193])\n",
      "logits: torch.Size([8, 193, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 164 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    578,   3545, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  13712,   1464],\n",
      "        [     2, 235281,  23144,  ...,    576,   4584,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  87743,   6584,   1464],\n",
      "        [     0,      0,      0,  ...,  37559,  13854,   1464],\n",
      "        [     0,      0,      0,  ...,  87743,   6584, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 193])\n",
      "logits: torch.Size([8, 193, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 168 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  60978,  ...,  84538,   2893, 235281],\n",
      "        [     0,      2, 235281,  ...,  87743,   6584,   1464],\n",
      "        [     0,      0,      0,  ...,  37559,  13854,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  60978,  ...,    476, 117027,   1464],\n",
      "        [     0,      0,      0,  ...,    604,   4547,   1464],\n",
      "        [     0,      0,      0,  ...,    604,   4547,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 155])\n",
      "logits: torch.Size([8, 155, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 172 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  87743,   6584, 235281],\n",
      "        [     0,      0,      0,  ...,    476, 117027,   1464],\n",
      "        [     0,      0,      0,  ...,    604,   4547,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1703,  38767,   1464],\n",
      "        [     0,      0,      0,  ...,    671,  46542,   1464],\n",
      "        [     0,      2, 235281,  ...,   1156,  46542, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 193])\n",
      "logits: torch.Size([8, 193, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 176 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  25487,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,   1703,  38767,   1464],\n",
      "        [     0,      0,      0,  ...,    671,  46542,   1464],\n",
      "        ...,\n",
      "        [     2, 235281, 167130,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   6589, 235281],\n",
      "        [     0,      0,      0,  ...,   1156, 100364,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 180 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1156,  46542,   1464],\n",
      "        [     2, 235281, 167130,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   6589, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1156,   9841, 235281],\n",
      "        [     0,      0,      0,  ...,  78991,   5054,   1464],\n",
      "        [     0,      0,      0,  ...,  78991,   5054,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 184 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,   9841, 235281],\n",
      "        [     0,      0,      0,  ...,  78991,   5054,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,   2267, 235281],\n",
      "        [     0,      0,      0,  ..., 235276,  61898,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  26193,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 196])\n",
      "logits: torch.Size([8, 196, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 188 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664,  77189,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2267, 235281],\n",
      "        [     0,      0,      0,  ..., 235276,  61898,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  28463,  11254, 235281],\n",
      "        [     0,      0,      0,  ...,   2301,   5100,   1464],\n",
      "        [     0,      0,      0,  ...,   2301,   5100,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 176])\n",
      "logits: torch.Size([8, 176, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 192 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  86013,   2893,   1464],\n",
      "        [     0,      0,      0,  ...,  28463,  11254, 235281],\n",
      "        [     0,      0,      0,  ...,   2301,   5100,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  10928,  11254,   1464],\n",
      "        [     2, 235281,  23427,  ...,    731,  19080, 235281],\n",
      "        [     0,      0,      0,  ...,  20995,   2611,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 223])\n",
      "logits: torch.Size([8, 223, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 196 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664,   6813,   1464],\n",
      "        [     0,      0,      0,  ...,  10928,  11254,   1464],\n",
      "        [     2, 235281,  23427,  ...,    731,  19080, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   6038,  11861, 235281],\n",
      "        [     0,      0,      0,  ...,    731,  19080,   1464],\n",
      "        [     0,      0,      0,  ...,    665, 168653, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 223])\n",
      "logits: torch.Size([8, 223, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 200 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  23427,  ...,    665, 168653,   1464],\n",
      "        [     0,      0,      0,  ...,   6038,  11861, 235281],\n",
      "        [     0,      0,      0,  ...,    731,  19080,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    675,   2474,   1464],\n",
      "        [     0,      0,      0,  ...,   2611,  35386,   1464],\n",
      "        [     0,      0,      0,  ...,   1582,   2611,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 223])\n",
      "logits: torch.Size([8, 223, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 204 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    774,  19080, 235281],\n",
      "        [     2, 235281,  23427,  ...,    675,   2474,   1464],\n",
      "        [     0,      0,      0,  ...,   2611,  35386,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  11861,   1464],\n",
      "        [     0,      0,      0,  ...,   7872,   2611,   1464],\n",
      "        [     0,      0,      0,  ...,   6086,  49138, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 220])\n",
      "logits: torch.Size([8, 220, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 208 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   6038,   2474,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  11861,   1464],\n",
      "        [     0,      0,      0,  ...,   7872,   2611,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   9662,   3584,   1464],\n",
      "        [     0,      0,      0,  ...,    575,  14328, 235281],\n",
      "        [     0,      0,      0,  ...,  22599,   2893,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 219])\n",
      "logits: torch.Size([8, 219, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 212 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   6086,  18216,   1464],\n",
      "        [     0,      0,      0,  ...,   9662,   3584,   1464],\n",
      "        [     0,      0,      0,  ...,    575,  14328, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,   6181, 235281],\n",
      "        [     0,      0,      0,  ...,   5250,  37944,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   2960,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 222])\n",
      "logits: torch.Size([8, 222, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 216 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  36752,  ...,    476,   4444,   1464],\n",
      "        [     0,      0,      0,  ...,    578,   6181, 235281],\n",
      "        [     0,      0,      0,  ...,   5250,  37944,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,  10605,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   1156,  17846],\n",
      "        [     0,      0,      0,  ...,  50915,   4592,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 222])\n",
      "logits: torch.Size([8, 222, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 220 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 155854,  35528, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  10605,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   1156,  17846],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  10730, 235281],\n",
      "        [     0,      0,      0,  ...,    978,  18292, 235281],\n",
      "        [     2, 235281,  70381,  ..., 235290,  33762,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 214])\n",
      "logits: torch.Size([8, 214, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 224 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,  14554,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  10730, 235281],\n",
      "        [     0,      0,      0,  ...,    978,  18292, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   6676, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  84434,   1464],\n",
      "        [     0,      0,      0,  ...,  10468,   2384,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 214])\n",
      "logits: torch.Size([8, 214, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 228 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  70381,  ..., 235290,  33762,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   6676, 235281],\n",
      "        [     0,      0,      2,  ...,    476,  84434,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  33762,  39187,   1464],\n",
      "        [     0,      0,      0,  ...,   7571,  34371, 235281],\n",
      "        [     0,      0,      0,  ...,   3610, 102104,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 206])\n",
      "logits: torch.Size([8, 206, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 232 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  70381,  ...,  10468,   2384,   1464],\n",
      "        [     0,      0,      2,  ...,  33762,  39187,   1464],\n",
      "        [     0,      0,      0,  ...,   7571,  34371, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  12604, 145156, 235281],\n",
      "        [     0,      0,      0,  ...,    840, 145156, 235281],\n",
      "        [     0,      0,      0,  ...,  13356,   7327,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 204])\n",
      "logits: torch.Size([8, 204, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 236 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    553,   6202,   1464],\n",
      "        [     0,      0,      0,  ...,  12604, 145156, 235281],\n",
      "        [     0,      0,      0,  ...,    840, 145156, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   9512, 235281],\n",
      "        [     2, 235281,  36752,  ...,   9646, 191098,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  21304,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 169])\n",
      "logits: torch.Size([8, 169, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 240 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,   7327,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   9512, 235281],\n",
      "        [     2, 235281,  36752,  ...,   9646, 191098,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   9512, 235281],\n",
      "        [     0,      0,      0,  ...,   9512,   3225,   1464],\n",
      "        [     0,      0,      0,  ...,  70624,   9512,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 169])\n",
      "logits: torch.Size([8, 169, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 244 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    578,   7539, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   9512, 235281],\n",
      "        [     0,      0,      0,  ...,   9512,   3225,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,  46045, 235281],\n",
      "        [     2, 235281,  41098,  ...,   3749,   5100,   1464],\n",
      "        [     0,      0,      0,  ...,    604,   7387, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 179])\n",
      "logits: torch.Size([8, 179, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 248 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 140009,   3225,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  46045, 235281],\n",
      "        [     2, 235281,  41098,  ...,   3749,   5100,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  16241, 235281],\n",
      "        [     0,      0,      0,  ...,   1889,   5078, 235281],\n",
      "        [     0,      2, 235281,  ...,    689,  20369,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 179])\n",
      "logits: torch.Size([8, 179, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 252 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,  16241, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  16241, 235281],\n",
      "        [     0,      0,      0,  ...,   1889,   5078, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  36099,   3741,   1464],\n",
      "        [     0,      0,      0,  ...,   4581,  25657, 235281],\n",
      "        [     0,      0,      0,  ...,   4581,  19283,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 178])\n",
      "logits: torch.Size([8, 178, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 256 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  42563,  23729,   1464],\n",
      "        [     0,      0,      0,  ...,  36099,   3741,   1464],\n",
      "        [     0,      0,      0,  ...,   4581,  25657, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 173694,   6268, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   9615,   1464],\n",
      "        [     2, 235281,  14706,  ..., 235275,  21898, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 203])\n",
      "logits: torch.Size([8, 203, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 260 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3515,   3142,   1464],\n",
      "        [     0,      0,      0,  ..., 173694,   6268, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   9615,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  11527,   5728, 235281],\n",
      "        [     0,      0,      0,  ...,   8103,  21898, 235281],\n",
      "        [     0,      0,      0,  ...,   1987,   2040,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 216])\n",
      "logits: torch.Size([8, 216, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 264 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  14706,  ...,  11527,   5728,   1464],\n",
      "        [     0,      0,      0,  ...,  11527,   5728, 235281],\n",
      "        [     0,      0,      0,  ...,   8103,  21898, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  21898,   1464],\n",
      "        [     0,      0,      0,  ...,   8115,   2377, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   9122,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 216])\n",
      "logits: torch.Size([8, 216, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 268 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  14706,  ...,   1987,   2040,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  21898,   1464],\n",
      "        [     0,      0,      0,  ...,   8115,   2377, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 111843,  24776, 235281],\n",
      "        [     0,      0,      0,  ...,    942,  34519,   1464],\n",
      "        [     0,      0,      0,  ...,    942,  34519,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 208])\n",
      "logits: torch.Size([8, 208, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 272 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  30323,   7479,   1464],\n",
      "        [     0,      0,      0,  ..., 111843,  24776, 235281],\n",
      "        [     0,      0,      0,  ...,    942,  34519,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   5086,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   1744, 235281],\n",
      "        [     2, 235281,  21853,  ...,  12181,   1069,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 210])\n",
      "logits: torch.Size([8, 210, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 276 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    591,   1387,  71982],\n",
      "        [     0,      0,      0,  ...,    476,   5086,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   1744, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   1069, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   1069,   1464],\n",
      "        [     2, 235281,  21853,  ...,   1069,  17143,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 213])\n",
      "logits: torch.Size([8, 213, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 280 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  21385,   1069,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   1069, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   1069,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  14123,  38636, 235281],\n",
      "        [     0,      0,      0,  ...,   3968,   3641,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  13795,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 213])\n",
      "logits: torch.Size([8, 213, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 284 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  21853,  ...,    576,   1069,   1464],\n",
      "        [     0,      0,      0,  ...,  14123,  38636, 235281],\n",
      "        [     0,      0,      0,  ...,   3968,   3641,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   2003,  74988,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2681,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2681,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 204])\n",
      "logits: torch.Size([8, 204, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 288 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,  13795, 235281],\n",
      "        [     0,      0,      0,  ...,   2003,  74988,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2681,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  10125,  ...,    573,  60718,   1464],\n",
      "        [     0,      0,      0,  ...,   8776,   2971, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  10246,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 182])\n",
      "logits: torch.Size([8, 182, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 292 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3309,  13618, 235281],\n",
      "        [     0,      0,      0,  ...,    573,  60718,   1464],\n",
      "        [     0,      0,      0,  ...,   8776,   2971, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  46295,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  15412,  17846],\n",
      "        [     0,      0,      0,  ...,    476,  12476,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 188])\n",
      "logits: torch.Size([8, 188, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 296 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  10125,  ...,  42476,   4191,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  46295,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  15412,  17846],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 235289,  19787,   1464],\n",
      "        [     0,      0,      0,  ...,    664, 220356,   1464],\n",
      "        [     0,      0,      0,  ...,  20627,   3687,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 188])\n",
      "logits: torch.Size([8, 188, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 300 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  12476,   1464],\n",
      "        [     0,      0,      0,  ..., 235289,  19787,   1464],\n",
      "        [     0,      0,      0,  ...,    664, 220356,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  14153,  ...,   3411,    665,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  38317,   1464],\n",
      "        [     0,      0,      0,  ..., 154110,   1736, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 180])\n",
      "logits: torch.Size([8, 180, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 304 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 216031,   5054, 235281],\n",
      "        [     2, 235281,  14153,  ...,   3411,    665,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  38317,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  13802,  26885,   1464],\n",
      "        [     0,      0,      0,  ...,  13802,  26885,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  22764, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 180])\n",
      "logits: torch.Size([8, 180, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 308 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,   3911, 235281],\n",
      "        [     0,      0,      0,  ...,  13802,  26885,   1464],\n",
      "        [     0,      0,      0,  ...,  13802,  26885,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  43959, 206439, 235281],\n",
      "        [     2, 235281,  14153,  ...,    689,   7091,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   3911,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 177])\n",
      "logits: torch.Size([8, 177, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 312 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,  59178, 235281],\n",
      "        [     0,      0,      0,  ...,  43959, 206439, 235281],\n",
      "        [     0,      0,      2,  ...,    689,   7091,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  94478,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   6589, 235281],\n",
      "        [     2, 235281,  27593,  ...,    689,  16036,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 179])\n",
      "logits: torch.Size([8, 179, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 316 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 166183,   3687,  71982],\n",
      "        [     0,      0,      0,  ...,  94478,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   6589, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    974,   6589, 235281],\n",
      "        [     0,      0,      0,  ...,    604,  53698, 235281],\n",
      "        [     2, 235281,  27593,  ...,  91710,   9841, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 320 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    604,  19396,   1464],\n",
      "        [     0,      0,      0,  ...,    974,   6589, 235281],\n",
      "        [     0,      0,      0,  ...,    604,  53698, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  16036,  53698, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  13265, 235281],\n",
      "        [     0,      0,      0,  ...,   7190,   1329,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 324 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  27593,  ...,  91710,   9841, 235281],\n",
      "        [     0,      0,      0,  ...,  16036,  53698, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  13265, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,   2003,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   3968,   1464],\n",
      "        [     0,      0,      0,  ...,    921,   2611, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 184])\n",
      "logits: torch.Size([8, 184, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 328 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,   5912,  17846],\n",
      "        [     2, 235281,  50398,  ...,    689,   2003,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   3968,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    671,  41500,   1464],\n",
      "        [     0,      0,      0,  ...,    921,   2611,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   5912,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 171])\n",
      "logits: torch.Size([8, 171, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 332 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  38642,   5580,   1464],\n",
      "        [     0,      0,      0,  ...,    671,  41500,   1464],\n",
      "        [     0,      0,      0,  ...,    921,   2611,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476, 206643,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  41014,   1464],\n",
      "        [     2, 235281,  50398,  ...,  41500,  66911, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 336 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476, 207713,   1464],\n",
      "        [     0,      0,      0,  ...,    476, 206643,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  41014,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  15733,  87433,   1464],\n",
      "        [     0,      0,      0,  ...,    577,   6719, 235281],\n",
      "        [     2, 235281,   2545,  ...,  27942,  11403, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 230])\n",
      "logits: torch.Size([8, 230, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 340 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  10334,  87433, 235281],\n",
      "        [     0,      0,      0,  ...,  15733,  87433,   1464],\n",
      "        [     0,      0,      0,  ...,    577,   6719, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,   6418,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   8205,   1464],\n",
      "        [     0,      0,      0,  ...,  29086,  15733,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 230])\n",
      "logits: torch.Size([8, 230, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 344 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,   2545,  ...,  27942,  11403,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   6418,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   8205,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,  27049,   1464],\n",
      "        [     0,      0,      0,  ...,  10709,    502,   1464],\n",
      "        [     0,      0,      0,  ...,  80944,   8205, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 217])\n",
      "logits: torch.Size([8, 217, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 348 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1767,  58432, 235281],\n",
      "        [     0,      0,      0,  ...,    573,  27049,   1464],\n",
      "        [     0,      0,      0,  ...,  10709,    502,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  20742,  ...,    798,    539,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   8692, 235281],\n",
      "        [     0,      0,      0,  ...,    671,  57877,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 219])\n",
      "logits: torch.Size([8, 219, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 352 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  10981,   2652,   1464],\n",
      "        [     2, 235281,  20742,  ...,    798,    539,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   8692, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    671,  16277, 235281],\n",
      "        [     0,      0,      0,  ...,    689,   4547,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   4444,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 219])\n",
      "logits: torch.Size([8, 219, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 356 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,  26580,   1464],\n",
      "        [     0,      0,      0,  ...,    671,  16277, 235281],\n",
      "        [     0,      0,      0,  ...,    689,   4547,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,   8692,   1464],\n",
      "        [     0,      0,      0,  ...,   6038,   2725, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  79450,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 218])\n",
      "logits: torch.Size([8, 218, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 360 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  14556,  ...,    573,   2621,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   8692,   1464],\n",
      "        [     0,      0,      0,  ...,   6038,   2725, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   5453, 235281],\n",
      "        [     0,      0,      0,  ...,  21293,   4955,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 218])\n",
      "logits: torch.Size([8, 218, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 364 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  16756,  16612, 235281],\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   5453, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  21293,   8890, 235281],\n",
      "        [     0,      0,      0,  ...,  21293,   8890, 235281],\n",
      "        [     0,      0,      0,  ...,    671,   4018,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 204])\n",
      "logits: torch.Size([8, 204, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 368 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  44505,  ...,  68516,    540, 235281],\n",
      "        [     0,      0,      0,  ...,  21293,   8890, 235281],\n",
      "        [     0,      0,      0,  ...,  21293,   8890, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  15055,   1464],\n",
      "        [     0,      0,      0,  ..., 235256,   2971, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   2971,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 372 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  44505,  ...,    611,   4368,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  15055,   1464],\n",
      "        [     0,      0,      0,  ..., 235256,   2971, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   2778,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  14328,   1464],\n",
      "        [     0,      0,      0,  ..., 235256,   2971,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 199])\n",
      "logits: torch.Size([8, 199, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 376 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,   2971, 235281],\n",
      "        [     0,      0,      0,  ...,    476,   2778,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  14328,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    671,   9659,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  14328,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  10177,  17846]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 170])\n",
      "logits: torch.Size([8, 170, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 380 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  53276,  ...,    604,   8012,   1464],\n",
      "        [     0,      0,      0,  ...,    671,   9659,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  14328,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  10177, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  10177, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   8203,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 170])\n",
      "logits: torch.Size([8, 170, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 384 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   2223,  18704,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  10177, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  10177, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,  25244, 235281],\n",
      "        [     2, 235281,  12933,  ..., 193693,   1812,   1464],\n",
      "        [     0,      0,      0,  ..., 104787,   4835,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 163])\n",
      "logits: torch.Size([8, 163, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 388 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  26626,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  25244, 235281],\n",
      "        [     0,      0,      0,  ..., 193693,   1812,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  12933,  ..., 134503,  29019,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  10827,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 177])\n",
      "logits: torch.Size([8, 177, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 392 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    578,   7739, 235281],\n",
      "        [     2, 235281,  12933,  ..., 134503,  29019,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   1658,   1464],\n",
      "        [     0,      0,      0,  ...,   8205,   3225, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  12254, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 177])\n",
      "logits: torch.Size([8, 177, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 396 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    685,   2960, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   1658,   1464],\n",
      "        [     0,      0,      0,  ...,   8205,   3225, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,  21809,   1464],\n",
      "        [     2, 235281,  28499,  ...,    685,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  12559, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 177])\n",
      "logits: torch.Size([8, 177, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 400 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  28499,  ...,    685,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  21809,   1464],\n",
      "        [     2, 235281,  28499,  ...,    685,   2960,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   9678,   1464],\n",
      "        [     0,      0,      0,  ...,    575,  44259, 235281],\n",
      "        [     0,      0,      0,  ...,  55348,   7479,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 177])\n",
      "logits: torch.Size([8, 177, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 404 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   9095,   1812,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   9678,   1464],\n",
      "        [     0,      0,      0,  ...,    575,  44259, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   4982, 235281],\n",
      "        [     2, 235281,  16926,  ...,   2960,   4584,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 203])\n",
      "logits: torch.Size([8, 203, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 408 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   8398,   1443,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   4982, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,  41191,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  41191,   1464],\n",
      "        [     0,      0,      0,  ...,   1987,   2040,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 203])\n",
      "logits: torch.Size([8, 203, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 412 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   5173,   9756,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  41191,   1464],\n",
      "        [     0,      2, 235281,  ...,    576,  41191,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  17536,  ...,   2951,  57732,   1464],\n",
      "        [     0,      0,      0,  ...,   1941,  46002,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  13170, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 416 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,  13141, 235281],\n",
      "        [     2, 235281,  17536,  ...,   2951,  57732,   1464],\n",
      "        [     0,      0,      0,  ...,   1941,  46002,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  46002, 235281],\n",
      "        [     2, 235281,  17536,  ...,   3104,  12758,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  13141,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 420 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,  13141, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  46002, 235281],\n",
      "        [     0,      0,      0,  ...,   3104,  12758,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  17536,  ...,    577,  10544,   1464],\n",
      "        [     0,      0,      0,  ...,  29138,    858,   1464],\n",
      "        [     0,      0,      0,  ..., 235256,   2971,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 209])\n",
      "logits: torch.Size([8, 209, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 424 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  47599,   1464],\n",
      "        [     2, 235281,  17536,  ...,    577,  10544,   1464],\n",
      "        [     0,      0,      0,  ...,  29138,    858,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578, 162683,   1464],\n",
      "        [     0,      0,      0,  ...,    578, 162683,   1464],\n",
      "        [     0,      0,      0,  ...,  12286,   1634, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 209])\n",
      "logits: torch.Size([8, 209, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 428 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,  18669,  17846],\n",
      "        [     0,      0,      0,  ...,    578, 162683,   1464],\n",
      "        [     0,      0,      0,  ...,    578, 162683,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,  18669,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   1634,   1464],\n",
      "        [     2, 235281,  26119,  ...,   1593, 160915, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 213])\n",
      "logits: torch.Size([8, 213, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 432 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 126570,   9113,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  18669,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   1634,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   2346,  35646,   1464],\n",
      "        [     0,      0,      0,  ...,    919, 160915, 235281],\n",
      "        [     2, 235281,  26119,  ...,    675, 160915,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 218])\n",
      "logits: torch.Size([8, 218, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 436 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    675,  35646,   1464],\n",
      "        [     0,      0,      0,  ...,   2346,  35646,   1464],\n",
      "        [     0,      0,      0,  ...,    919, 160915, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  38631,   2480, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  21333,   1464],\n",
      "        [     0,      0,      0,  ...,  10626,   6996,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 218])\n",
      "logits: torch.Size([8, 218, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 440 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  26119,  ...,  54969,   8205,   1464],\n",
      "        [     0,      0,      0,  ...,  38631,   2480, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  21333,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  10159,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   8540, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   1156,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 444 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,   9662, 235281],\n",
      "        [     2, 235281,  27313,  ...,    689,  10159,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   8540, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1593,    665, 235281],\n",
      "        [     0,      0,      0,  ..., 235269,  11124, 235281],\n",
      "        [     0,      0,      0,  ...,    671,  26513,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 193])\n",
      "logits: torch.Size([8, 193, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 448 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1865,  22275,   1464],\n",
      "        [     0,      0,      0,  ...,   1593,    665, 235281],\n",
      "        [     0,      0,      0,  ..., 235269,  11124, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  17200,   1464],\n",
      "        [     0,      0,      0,  ...,  37553,  10390, 235281],\n",
      "        [     2, 235281,  50398,  ...,  12286,   8398,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 201])\n",
      "logits: torch.Size([8, 201, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 452 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1593,    665,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  17200,   1464],\n",
      "        [     0,      0,      0,  ...,  37553,  10390, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  12286,   8398, 235281],\n",
      "        [     0,      0,      0,  ...,   1767, 173940,   1464],\n",
      "        [     0,      0,      0,  ...,    575, 173940, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 201])\n",
      "logits: torch.Size([8, 201, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 456 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1767, 173940,   1464],\n",
      "        [     0,      0,      0,  ...,  12286,   8398, 235281],\n",
      "        [     0,      0,      0,  ...,   1767, 173940,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  12150,   2960, 235281],\n",
      "        [     0,      0,      0,  ...,  12150,   2960, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   9615,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 208])\n",
      "logits: torch.Size([8, 208, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 460 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  50398,  ...,    573,   2590,   1464],\n",
      "        [     0,      0,      0,  ...,  12150,   2960, 235281],\n",
      "        [     0,      0,      0,  ...,  12150,   2960, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  68516,    540, 235281],\n",
      "        [     0,      0,      0,  ...,  50212,   2960, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   9615,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 208])\n",
      "logits: torch.Size([8, 208, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 464 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    578,  15983,   1464],\n",
      "        [     0,      0,      0,  ...,  68516,    540, 235281],\n",
      "        [     0,      0,      0,  ...,  50212,   2960, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  37524, 130591, 235281],\n",
      "        [     2, 235281, 100349,  ...,    689,  46002,   1464],\n",
      "        [     0,      2, 235281,  ...,    573, 172239,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 204])\n",
      "logits: torch.Size([8, 204, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 468 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,   8360,   1464],\n",
      "        [     0,      0,      0,  ...,  37524, 130591, 235281],\n",
      "        [     2, 235281, 100349,  ...,    689,  46002,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,  46002, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  12776,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  12776,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 204])\n",
      "logits: torch.Size([8, 204, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 472 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    475, 117494,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  46002, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  12776,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    604,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   1855, 235281],\n",
      "        [     0,      0,      0,  ...,   3515,   1855,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 209])\n",
      "logits: torch.Size([8, 209, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 476 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281, 100349,  ...,    578, 164935,   1464],\n",
      "        [     0,      0,      0,  ...,    604,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   1855, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3515,   1855, 235281],\n",
      "        [     0,      0,      0,  ...,   3515,  41154, 235281],\n",
      "        [     0,      0,      0,  ...,  13266,   1411, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 209])\n",
      "logits: torch.Size([8, 209, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 480 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3515,  41154, 235281],\n",
      "        [     0,      0,      0,  ...,   3515,   1855, 235281],\n",
      "        [     0,      0,      0,  ...,   3515,  41154, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3515,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   1855,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   2971,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 198])\n",
      "logits: torch.Size([8, 198, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 484 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      2, 235281,  ...,  27290, 235265,    664],\n",
      "        [     0,      0,      0,  ...,   3515,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   1855,   1464],\n",
      "        ...,\n",
      "        [     2, 235281, 201328,  ...,   3515,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,    664,  18001,   1464]]), 'attention_mask': tensor([[0, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 199])\n",
      "logits: torch.Size([8, 199, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 488 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  41725,  20837,   1464],\n",
      "        [     2, 235281, 201328,  ...,   3515,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   2971,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  37565,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   2971,   1464],\n",
      "        [     0,      0,      0,  ..., 235256,   2971,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 199])\n",
      "logits: torch.Size([8, 199, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 492 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281, 201328,  ...,    689,   9420,   1464],\n",
      "        [     0,      0,      0,  ...,  37565,   2971,   1464],\n",
      "        [     0,      0,      2,  ...,   3515,   2971,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   1552,   1464],\n",
      "        [     0,      0,      0,  ...,    708,  44169, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   4460,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 195])\n",
      "logits: torch.Size([8, 195, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 496 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281, 201328,  ...,    476,   1552,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   1552,   1464],\n",
      "        [     0,      0,      0,  ...,    708,  44169, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,   7652, 235281],\n",
      "        [     0,      0,      0,  ...,    576,  10996,   1464],\n",
      "        [     0,      0,      0,  ...,  73308,   9841,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 500 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   4158,   1913,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   7652, 235281],\n",
      "        [     2, 235281,  14556,  ...,    576,  10996,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3486,   8914, 235281],\n",
      "        [     0,      0,      0,  ...,    671,  73218,   1464],\n",
      "        [     0,      0,      0,  ...,   8914,   3515,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 175])\n",
      "logits: torch.Size([8, 175, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 504 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3486,   4323, 235281],\n",
      "        [     0,      0,      0,  ...,   3486,   8914, 235281],\n",
      "        [     2, 235281,    845,  ...,    671,  73218,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   8914,   3515, 235281],\n",
      "        [     0,      0,      0,  ...,    689,  47913,   1464],\n",
      "        [     0,      0,      0,  ...,   3486,   4323,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 158])\n",
      "logits: torch.Size([8, 158, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 508 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   8914,   3515, 235281],\n",
      "        [     0,      0,      0,  ...,   8914,   3515, 235281],\n",
      "        [     0,      0,      0,  ...,    689,  47913,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,    845,  ...,   1544,    605,   1464],\n",
      "        [     0,      0,      0,  ..., 235289,   5190,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  29351, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 166])\n",
      "logits: torch.Size([8, 166, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 512 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664,  58483,   1464],\n",
      "        [     0,      0,      0,  ...,   1544,    605,   1464],\n",
      "        [     0,      0,      0,  ..., 235289,   5190,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3515,   1634,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   1634, 235281],\n",
      "        [     2, 235281,  40792,  ...,   1156,  18976,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 182])\n",
      "logits: torch.Size([8, 182, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 516 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,  18669,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   1634,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   1634, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  14328,   1464],\n",
      "        [     0,      0,      0,  ...,   7673,  55254, 235281],\n",
      "        [     0,      0,      0,  ...,    685,  41191,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 182])\n",
      "logits: torch.Size([8, 182, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 520 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  40792,  ...,    573,  18976,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  14328,   1464],\n",
      "        [     0,      0,      0,  ...,   7673,  55254, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1277,   9512, 235281],\n",
      "        [     0,      0,      0,  ...,    578,   9512,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  28294,  17846]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 176])\n",
      "logits: torch.Size([8, 176, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 524 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664, 206194,   1464],\n",
      "        [     0,      0,      0,  ...,   1277,   9512, 235281],\n",
      "        [     2, 235281,   9188,  ...,    578,   9512,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    685, 190492,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,   2893, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  89395, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 162])\n",
      "logits: torch.Size([8, 162, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 528 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  47610,   5097,   1464],\n",
      "        [     0,      0,      0,  ...,    685, 190492,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,   2893, 235281],\n",
      "        ...,\n",
      "        [     2, 235281,  23459,  ...,   6719,   4783, 235281],\n",
      "        [     0,      0,      0,  ...,   1188,   1629,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   5239,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 188])\n",
      "logits: torch.Size([8, 188, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 532 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  34563,  17175,   1464],\n",
      "        [     0,      2, 235281,  ...,   6719,   4783, 235281],\n",
      "        [     0,      0,      0,  ...,   1188,   1629,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  23459,  ...,   3733,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,  58318,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,  58318,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 536 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,   5239, 235281],\n",
      "        [     2, 235281,  23459,  ...,   3733,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,  58318,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    671,   4018,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   7217,   1464],\n",
      "        [     0,      0,      0,  ...,    604, 118254,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 540 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    731,  23603, 235281],\n",
      "        [     0,      0,      0,  ...,    671,   4018,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   7217,   1464],\n",
      "        ...,\n",
      "        [     2, 235281, 110184,  ...,  92206,   1769,   1464],\n",
      "        [     0,      0,      0,  ...,    671,   8205,   1464],\n",
      "        [     0,      0,      0,  ...,   6711,   1702,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 544 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  11257,  24572, 235281],\n",
      "        [     2, 235281, 110184,  ...,  92206,   1769,   1464],\n",
      "        [     0,      0,      0,  ...,    671,   8205,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   2904, 101868, 235281],\n",
      "        [     0,      0,      0,  ...,    671,   8205, 235281],\n",
      "        [     0,      0,      0,  ...,  18892,  17611,  71982]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 548 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    671,   8205, 235281],\n",
      "        [     0,      0,      0,  ...,   2904, 101868, 235281],\n",
      "        [     0,      0,      0,  ...,    671,   8205, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3383,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,   1156, 173940,   1464],\n",
      "        [     2, 235281,  97123,  ...,    476,  95996, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 200])\n",
      "logits: torch.Size([8, 200, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 552 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  35918,   1464],\n",
      "        [     0,      0,      0,  ...,   3383,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,   1156, 173940,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  97123,  ...,   8012,  43105,   1464],\n",
      "        [     0,      0,      0,  ...,  16731,   1735,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2206,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 219])\n",
      "logits: torch.Size([8, 219, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 556 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  16731,   1735,   1464],\n",
      "        [     2, 235281,  97123,  ...,   8012,  43105,   1464],\n",
      "        [     0,      0,      0,  ...,  16731,   1735,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  31771,   3954, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   1450, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  33263,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 219])\n",
      "logits: torch.Size([8, 219, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 560 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 235256,   2206, 235281],\n",
      "        [     0,      0,      0,  ...,  31771,   3954, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   1450, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   2206,  18384,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   3954,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2971, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 214])\n",
      "logits: torch.Size([8, 214, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 564 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  97123,  ...,   1156,  25265,   1464],\n",
      "        [     0,      0,      0,  ...,   2206,  18384,   1464],\n",
      "        [     0,      0,      0,  ...,    689,   3954,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   4282,   6202,   1464],\n",
      "        [     0,      0,      0,  ...,   1969,   2359, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   5330, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 214])\n",
      "logits: torch.Size([8, 214, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 568 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1546,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,   4282,   6202,   1464],\n",
      "        [     0,      0,      0,  ...,   1969,   2359, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  22423,   1464],\n",
      "        [     2, 235281, 172836,  ...,    576,  41916, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 208])\n",
      "logits: torch.Size([8, 208, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 572 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  20279,   2359, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   2971,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  22423,   1464],\n",
      "        ...,\n",
      "        [     2, 235281, 172836,  ...,  14533,   3614,   1464],\n",
      "        [     0,      0,      0,  ...,  13340,  11755, 235281],\n",
      "        [     0,      0,      0,  ...,    573,  69662,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 213])\n",
      "logits: torch.Size([8, 213, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 576 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  29169, 124362,   1464],\n",
      "        [     2, 235281, 172836,  ...,  14533,   3614,   1464],\n",
      "        [     0,      0,      0,  ...,  13340,  11755, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  96706,  11755, 235281],\n",
      "        [     0,      0,      0,  ..., 101320,  11755, 235281],\n",
      "        [     0,      0,      0,  ...,    476,   5265,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 213])\n",
      "logits: torch.Size([8, 213, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 580 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  25399,  11755, 235281],\n",
      "        [     0,      0,      0,  ...,  96706,  11755, 235281],\n",
      "        [     0,      0,      0,  ..., 101320,  11755, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,  69662,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  69662,   1464],\n",
      "        [     2, 235281, 172836,  ..., 235290,  19098,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 207])\n",
      "logits: torch.Size([8, 207, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 584 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  25399,   2730,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  69662,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  69662,   1464],\n",
      "        ...,\n",
      "        [     2, 235281, 172836,  ...,    780, 154439,   1464],\n",
      "        [     0,      0,      0,  ..., 104652,  11755,   1464],\n",
      "        [     0,      0,      0,  ...,   6427,   5158, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 222])\n",
      "logits: torch.Size([8, 222, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 588 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  96706,  11755,   1464],\n",
      "        [     2, 235281, 172836,  ...,    780, 154439,   1464],\n",
      "        [     0,      0,      0,  ..., 104652,  11755,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,   6682,   1464],\n",
      "        [     0,      0,      0,  ...,   2212,  17172, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  33419,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 222])\n",
      "logits: torch.Size([8, 222, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 592 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  96794,  ...,   6910,   6682,   1464],\n",
      "        [     0,      0,      0,  ...,    578,   6682,   1464],\n",
      "        [     0,      0,      0,  ...,   2212,  17172, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  21437,   4547,   1464],\n",
      "        [     0,      0,      0,  ...,    731,   1461,   1464],\n",
      "        [     0,      0,      0,  ...,   5027,    575, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 204])\n",
      "logits: torch.Size([8, 204, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 596 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    978,   9160, 235281],\n",
      "        [     0,      0,      0,  ...,  21437,   4547,   1464],\n",
      "        [     0,      0,      0,  ...,    731,   1461,   1464],\n",
      "        ...,\n",
      "        [     0,      2, 235281,  ...,    731,   2003, 235281],\n",
      "        [     2, 235281,   2907,  ...,    731,   2003,   1464],\n",
      "        [     0,      0,      0,  ...,    731,   2003,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 600 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    576,  19237,   1464],\n",
      "        [     0,      2, 235281,  ...,    731,   2003, 235281],\n",
      "        [     2, 235281,   2907,  ...,    731,   2003,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,   2907,  ...,    731,   2003,   1464],\n",
      "        [     2, 235281,   2907,  ...,    731,   2003,   1464],\n",
      "        [     0,      0,      0,  ...,    604,  25362, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 604 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    731,   2003, 235281],\n",
      "        [     0,      0,      0,  ...,    731,   2003,   1464],\n",
      "        [     0,      0,      0,  ...,    731,   2003,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  45713,   1132,   1464],\n",
      "        [     0,      0,      0,  ...,  45713,   1132, 235281],\n",
      "        [     0,      0,      0,  ...,   1501,  25362, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 196])\n",
      "logits: torch.Size([8, 196, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 608 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281, 161817,  ...,  45713,   1132,   1464],\n",
      "        [     0,      0,      0,  ...,  45713,   1132,   1464],\n",
      "        [     0,      0,      0,  ...,  45713,   1132, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  31740,   1464],\n",
      "        [     0,      0,      0,  ..., 235280,  21737,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  19419,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 196])\n",
      "logits: torch.Size([8, 196, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 612 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281, 161817,  ...,    575,  51225,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  31740,   1464],\n",
      "        [     0,      0,      0,  ..., 235280,  21737,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,   6589,   1464],\n",
      "        [     0,      0,      0,  ...,  18074,   2003,   1464],\n",
      "        [     0,      0,      0,  ...,  34547,   2003, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 186])\n",
      "logits: torch.Size([8, 186, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 616 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  23729, 235281],\n",
      "        [     2, 235281,  12703,  ...,    578,   6589,   1464],\n",
      "        [     0,      0,      0,  ...,  18074,   2003,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  18074,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,  34547,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  23729,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 157])\n",
      "logits: torch.Size([8, 157, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 620 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    604,   1763,   1464],\n",
      "        [     0,      0,      0,  ...,  18074,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,  34547,   2960,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  20237,  ...,    614,  74571, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  10240,   1464],\n",
      "        [     0,      0,      0,  ...,   2587,   8555, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 207])\n",
      "logits: torch.Size([8, 207, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 624 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  15983,   2960,   1464],\n",
      "        [     2, 235281,  20237,  ...,    614,  74571, 235281],\n",
      "        [     0,      0,      0,  ...,    476,  10240,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 116019, 167870,   1464],\n",
      "        [     0,      0,      0,  ...,  22227, 148071, 235281],\n",
      "        [     0,      0,      0,  ...,    573,   2590,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 207])\n",
      "logits: torch.Size([8, 207, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 628 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  96166,  ...,   2587,   8555,   1464],\n",
      "        [     0,      0,      0,  ..., 116019, 167870,   1464],\n",
      "        [     0,      0,      0,  ...,  22227, 148071, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   6589, 235281],\n",
      "        [     0,      0,      0,  ...,    689, 202233,   1464],\n",
      "        [     0,      0,      0,  ...,   1634,   7217,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 159])\n",
      "logits: torch.Size([8, 159, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 632 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573, 134181,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   6589, 235281],\n",
      "        [     0,      0,      0,  ...,    689, 202233,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  18200,  ...,   1156,   2960,   1464],\n",
      "        [     0,      0,      2,  ...,    604,  59548,   1464],\n",
      "        [     0,      0,      0,  ...,    604,  13565,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 171])\n",
      "logits: torch.Size([8, 171, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 636 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,  21846, 235281],\n",
      "        [     0,      0,      0,  ...,   1156,   2960,   1464],\n",
      "        [     0,      0,      0,  ...,    604,  59548,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    689,   2145,   1464],\n",
      "        [     0,      0,      0,  ..., 197908,   5453,   1464],\n",
      "        [     0,      0,      2,  ...,    573,  40719,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 222])\n",
      "logits: torch.Size([8, 222, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 640 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  25898,  ...,   2550,   4018, 235281],\n",
      "        [     0,      0,      0,  ...,    689,   2145,   1464],\n",
      "        [     0,      0,      0,  ..., 197908,   5453,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    604, 105156,   1464],\n",
      "        [     0,      0,      0,  ...,  47042,   4829,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  58169, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 222])\n",
      "logits: torch.Size([8, 222, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 644 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   4871,   7652, 235281],\n",
      "        [     0,      0,      0,  ...,    604, 105156,   1464],\n",
      "        [     0,      0,      0,  ...,  47042,   4829,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 161344,   7743, 235281],\n",
      "        [     0,      0,      0,  ...,   4829,   3584,   1464],\n",
      "        [     2, 235281,   2162,  ...,    476,  58169,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 187])\n",
      "logits: torch.Size([8, 187, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 648 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 161344,   3426, 235281],\n",
      "        [     0,      0,      0,  ..., 161344,   7743, 235281],\n",
      "        [     0,      0,      0,  ...,   4829,   3584,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,  37553, 235281],\n",
      "        [     0,      0,      0,  ...,  26097,   5612,   1464],\n",
      "        [     0,      0,      0,  ...,   3515,   2971, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 187])\n",
      "logits: torch.Size([8, 187, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 652 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 162593,   1280,   1464],\n",
      "        [     0,      0,      0,  ...,    578,  37553, 235281],\n",
      "        [     0,      0,      0,  ...,  26097,   5612,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,  37553,   1464],\n",
      "        [     0,      0,      0,  ...,   8096,   9113, 235281],\n",
      "        [     2, 235281,  44515,  ...,    578,   4835,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 656 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  37553,   1464],\n",
      "        [     0,      0,      0,  ...,   8096,   9113, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    578,   4835,   1464],\n",
      "        [     0,      0,      0,  ...,   9095,   5191,   1464],\n",
      "        [     0,      0,      0,  ...,   9095,   5191, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 198])\n",
      "logits: torch.Size([8, 198, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 660 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   9095,   4562,   1464],\n",
      "        [     0,      0,      0,  ...,    578,   4835,   1464],\n",
      "        [     0,      0,      0,  ...,   9095,   5191,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  20566, 235265,    664],\n",
      "        [     2, 235281,  44515,  ...,   3464,   2416,   1464],\n",
      "        [     0,      0,      0,  ...,   3695,   4835,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 221])\n",
      "logits: torch.Size([8, 221, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 664 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   8096,   5191, 235281],\n",
      "        [     0,      0,      0,  ...,  20566, 235265,    664],\n",
      "        [     2, 235281,  44515,  ...,   3464,   2416,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    575,  13041, 235281],\n",
      "        [     0,      0,      0,  ...,   3359,  17611,   1464],\n",
      "        [     0,      0,      0,  ...,   3359,  17611,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 221])\n",
      "logits: torch.Size([8, 221, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 668 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664,  28484,   1464],\n",
      "        [     0,      0,      0,  ...,    575,  13041, 235281],\n",
      "        [     2, 235281, 172836,  ...,   3359,  17611,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        [     0,      0,      0,  ...,  11859,    740,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   5054, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 206])\n",
      "logits: torch.Size([8, 206, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 672 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,   9615,   1464],\n",
      "        [     0,      0,      0,  ...,    476,   3733,   1464],\n",
      "        [     2, 235281, 172836,  ...,  11859,    740,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    576,  63418,   1464],\n",
      "        [     0,      0,      0,  ...,    671,   8205, 235281],\n",
      "        [     0,      0,      0,  ...,    603,   7673, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 199])\n",
      "logits: torch.Size([8, 199, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 676 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   5086,   2377,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  63418,   1464],\n",
      "        [     0,      0,      0,  ...,    671,   8205, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   7408,   1243,   1464],\n",
      "        [     0,      0,      0,  ..., 103957,   5054,   1464],\n",
      "        [     2, 235281, 102070,  ...,    573,   1411,  17846]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 202])\n",
      "logits: torch.Size([8, 202, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 680 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   5086,   2377, 235281],\n",
      "        [     0,      0,      0,  ...,   7408,   1243,   1464],\n",
      "        [     0,      0,      0,  ..., 103957,   5054,   1464],\n",
      "        ...,\n",
      "        [     2, 235281, 102070,  ...,    573,   1411,   1464],\n",
      "        [     0,      0,      0,  ...,  11653,   5229,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   1411, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 215])\n",
      "logits: torch.Size([8, 215, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 684 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3311,   5229,   1464],\n",
      "        [     2, 235281, 102070,  ...,    573,   1411,   1464],\n",
      "        [     0,      0,      0,  ...,  11653,   5229,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3821,   5033, 235281],\n",
      "        [     0,      0,      0,  ...,   1853,   3772, 235281],\n",
      "        [     0,      0,      0,  ..., 235290,   5436, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 215])\n",
      "logits: torch.Size([8, 215, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 688 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1277, 145326, 235281],\n",
      "        [     0,      0,      0,  ...,   3821,   5033, 235281],\n",
      "        [     0,      0,      0,  ...,   1853,   3772, 235281],\n",
      "        ...,\n",
      "        [     2, 235281, 102070,  ...,  12581,   2000,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   3001,   1464],\n",
      "        [     0,      0,      0,  ...,    675,  30562, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 190])\n",
      "logits: torch.Size([8, 190, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 692 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  30765,   1411, 235281],\n",
      "        [     2, 235281, 102070,  ...,  12581,   2000,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   3001,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  17839,   3967,   1464],\n",
      "        [     0,      0,      0,  ...,    731,  30562,   1464],\n",
      "        [     0,      0,      0,  ...,   6050,   4955,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 190])\n",
      "logits: torch.Size([8, 190, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 696 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,   3967,   1464],\n",
      "        [     0,      0,      0,  ...,  17839,   3967,   1464],\n",
      "        [     0,      0,      0,  ...,    731,  30562,   1464],\n",
      "        ...,\n",
      "        [     2, 235281,  95542,  ...,    573,   8816, 235281],\n",
      "        [     0,      0,      2,  ...,    578, 105661,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  35646, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 198])\n",
      "logits: torch.Size([8, 198, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 700 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   1501,   3967,   1464],\n",
      "        [     2, 235281,  95542,  ...,    573,   8816, 235281],\n",
      "        [     0,      0,      2,  ...,    578, 105661,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   8205,  22926, 235281],\n",
      "        [     0,      0,      0,  ...,   4948,  44097,   1464],\n",
      "        [     0,      0,      0,  ...,   1156,   8398,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 198])\n",
      "logits: torch.Size([8, 198, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 704 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  12286,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,   8205,  22926, 235281],\n",
      "        [     0,      0,      0,  ...,   4948,  44097,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,   2971, 235281],\n",
      "        [     2, 235281,  23459,  ...,    576,   1450,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  89642,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 181])\n",
      "logits: torch.Size([8, 181, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 708 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    578,  41521,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   2971, 235281],\n",
      "        [     2, 235281,  23459,  ...,    576,   1450,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1767,   8398,   1464],\n",
      "        [     2, 235281,  23459,  ...,    689,  31540, 235281],\n",
      "        [     0,      0,      0,  ...,    774, 134379, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 181])\n",
      "logits: torch.Size([8, 181, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 712 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    575,  31029, 235281],\n",
      "        [     0,      0,      0,  ...,   1767,   8398,   1464],\n",
      "        [     0,      0,      2,  ...,    689,  31540, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1009,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  31540,   1464],\n",
      "        [     2, 235281,  97123,  ...,   1156,  58318, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 183])\n",
      "logits: torch.Size([8, 183, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 716 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    573,  31540,   1464],\n",
      "        [     0,      0,      0,  ...,   1009,   8398,   1464],\n",
      "        [     0,      0,      0,  ...,    573,  31540,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  53266, 118351,   1464],\n",
      "        [     0,      0,      0,  ...,  81504,  24590, 235281],\n",
      "        [     0,      0,      0,  ...,    578,  19918,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 720 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  97123,  ...,    573,   9615,   1464],\n",
      "        [     0,      0,      0,  ...,  53266, 118351,   1464],\n",
      "        [     0,      0,      0,  ...,  81504,  24590, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    573,   3142,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  19918,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  19918,   1464]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 189])\n",
      "logits: torch.Size([8, 189, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 724 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     2, 235281,  97123,  ...,    689,  19918,   1464],\n",
      "        [     0,      0,      0,  ...,    573,   3142,   1464],\n",
      "        [     0,      0,      0,  ...,    576,  19918,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  92338,  12962,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  33390, 235281],\n",
      "        [     0,      0,      0,  ...,  92338,  12962, 235281]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 179])\n",
      "logits: torch.Size([8, 179, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 728 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  33390, 235281],\n",
      "        [     0,      0,      0,  ...,  92338,  12962,   1464],\n",
      "        [     0,      0,      0,  ...,    476,  33390, 235281],\n",
      "        ...,\n",
      "        [     2, 235281,  27313,  ...,  92338,  28966,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   3838, 235281],\n",
      "        [     0,      0,      0,  ...,    671,  11588,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 176])\n",
      "logits: torch.Size([8, 176, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 732 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,  33390,   1464],\n",
      "        [     2, 235281,  27313,  ...,  92338,  28966,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   3838, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   3724,   7257, 235281],\n",
      "        [     0,      0,      0,  ...,   4844,   1160, 235281],\n",
      "        [     0,      0,      0,  ...,    476,   3838, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 176])\n",
      "logits: torch.Size([8, 176, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 736 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   3724,   1411, 235281],\n",
      "        [     0,      0,      0,  ...,   3724,   7257, 235281],\n",
      "        [     0,      0,      0,  ...,   4844,   1160, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   5678,   5728,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   3838,   1464],\n",
      "        [     2, 235281,  17113,  ...,    576,   3838,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 141])\n",
      "logits: torch.Size([8, 141, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 740 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    476,   5091,   1464],\n",
      "        [     0,      0,      0,  ...,   5678,   5728,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   3838,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 235289,   4844,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   3838,   1464],\n",
      "        [     2, 235281,   7032,  ...,    578,   8123, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 191])\n",
      "logits: torch.Size([8, 191, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 744 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  37223,   4844,   1464],\n",
      "        [     0,      0,      0,  ..., 235289,   4844,   1464],\n",
      "        [     0,      0,      0,  ...,    576,   3838,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  12918,  18303, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   2611, 235281],\n",
      "        [     2, 235281,   7032,  ...,    578,   8123,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 748 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      2,  ...,  12918,   2611,   1464],\n",
      "        [     0,      0,      0,  ...,  12918,  18303, 235281],\n",
      "        [     0,      0,      0,  ...,    576,   2611, 235281],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,    575,  10164,   1464],\n",
      "        [     0,      0,      0,  ...,    664,  22051,   1464],\n",
      "        [     0,      0,      0,  ...,    689, 109649, 235281]]), 'attention_mask': tensor([[0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 752 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    664,  29860,   1464],\n",
      "        [     2, 235281,   7032,  ...,    575,  10164,   1464],\n",
      "        [     0,      0,      0,  ...,    664,  22051,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ..., 141521,  23710, 235281],\n",
      "        [     0,      0,      0,  ..., 235269,   3687,   1464],\n",
      "        [     0,      0,      0,  ...,    689,  18074,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 183])\n",
      "logits: torch.Size([8, 183, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 756 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,   5342,   4473,   1464],\n",
      "        [     0,      0,      0,  ..., 141521,  23710, 235281],\n",
      "        [     2, 235281,   1914,  ..., 235269,   3687,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  17663,  22087, 235281],\n",
      "        [     0,      0,      2,  ...,    689,  10478,   1464],\n",
      "        [     0,      0,      0,  ...,   5250,   4368,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 170])\n",
      "logits: torch.Size([8, 170, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 760 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,    689,  18074,   1464],\n",
      "        [     0,      0,      0,  ...,  17663,  22087, 235281],\n",
      "        [     0,      0,      0,  ...,    689,  10478,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,   1501,  12659,   1464],\n",
      "        [     0,      2, 235281,  ...,   1501,  12659,   1464],\n",
      "        [     2, 235281,  18420,  ...,    575,   4656, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 172])\n",
      "logits: torch.Size([8, 172, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 764 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ...,  21299,  17663, 235281],\n",
      "        [     0,      0,      0,  ...,   1501,  12659,   1464],\n",
      "        [     0,      0,      0,  ...,   1501,  12659,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  21526,  66579, 235281],\n",
      "        [     0,      0,      0,  ...,    611,   4368,   1464],\n",
      "        [     0,      0,      0,  ...,  38285,   7133, 235281]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 192])\n",
      "logits: torch.Size([8, 192, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n",
      "i: 768 < len(inputs): 1169\n",
      "batch_patch_pos dtype (int?): torch.int64\n",
      "batch_repr_index dtype (int?): torch.int64\n",
      "inputs len : 8\n",
      "{'input_ids': tensor([[     0,      0,      0,  ..., 235256,   1634,   1464],\n",
      "        [     0,      0,      0,  ...,  21526,  66579, 235281],\n",
      "        [     0,      0,      0,  ...,    611,   4368,   1464],\n",
      "        ...,\n",
      "        [     0,      0,      0,  ...,  14194,   8069, 235281],\n",
      "        [     2, 235281,  11447,  ...,   8096,   5191,   1464],\n",
      "        [     0,      0,      0,  ...,   9095,   3096,   1464]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
      "mask: torch.Size([8, 218])\n",
      "logits: torch.Size([8, 218, 256000])\n",
      "reprs: torch.Size([0, 26, 2304])\n"
     ]
    }
   ],
   "source": [
    "paper_pairs = [[\"de\", \"it\"], [\"nl\", \"fi\"], [\"zh\", \"es\"], [\"es\", \"ru\"], [\"ru\", \"ko\"]]\n",
    "paper_ins = [\"de\", \"nl\", \"zh\", \"es\", \"ru\"]\n",
    "test_pairs = [[\"es\", \"fr\"], [\"es\", \"de\"]]\n",
    "hard_langs = [\"ko\", \"ja\", \"et\", \"fi\"]\n",
    "easy_langs = [\"en\", \"fr\", \"zh\", \"de\"]\n",
    "paper_args = [\n",
    "    ([[\"es\", \"fr\"], [\"es\", \"de\"]], \"en\"),\n",
    "    (paper_pairs, \"zh\"),\n",
    "    ([[\"it\", \"es\"], [\"it\", \"de\"]], \"fr\"),\n",
    "    (paper_pairs, \"en\"),\n",
    "    ([[\"en\", hl] for hl in hard_langs], \"fr\"),\n",
    "    ([[\"hi\", el] for el in easy_langs], \"et\"),\n",
    "]\n",
    "if DEBUG:\n",
    "    paper_args = [paper_args[0]]\n",
    "for pargs in paper_args:\n",
    "    try:\n",
    "        plot_args = experiment(*pargs)\n",
    "    finally:\n",
    "        gc.collect()\n",
    "        th.cuda.empty_cache()\n",
    "        th.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
